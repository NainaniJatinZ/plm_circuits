{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to finetuning (Python 3.10.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4835b-e467-4212-a505-f21847be6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In IPython\n",
      "Set autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "In IPython\n",
      "Set autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and functions from helper modules\n",
    "import sys\n",
    "sys.path.append('../plm_circuits')\n",
    "\n",
    "# Import utility functions\n",
    "from helpers.utils import (\n",
    "    clear_memory,\n",
    "    load_esm,\n",
    "    load_sae_prot,\n",
    "    mask_flanks_segment,\n",
    "    patching_metric,\n",
    "    cleanup_cuda\n",
    ")\n",
    "\n",
    "# Import attribution functions\n",
    "from attribution import (\n",
    "    integrated_gradients_sae,\n",
    "    topk_sae_err_pt\n",
    ")\n",
    "\n",
    "# Import hook classes\n",
    "from hook_manager import SAEHookProt\n",
    "\n",
    "# Additional imports\n",
    "import json\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316ac5d-077a-4df4-a128-8995231a60eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device and load models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load ESM-2 model\n",
    "esm_transformer, batch_converter, esm2_alphabet = load_esm(33, device=device)\n",
    "\n",
    "# Load SAEs for multiple layers\n",
    "main_layers = [4, 8, 12, 16, 20, 24, 28]\n",
    "saes = []\n",
    "for layer in main_layers:\n",
    "    sae_model = load_sae_prot(ESM_DIM=1280, SAE_DIM=4096, LAYER=layer, device=device)\n",
    "    saes.append(sae_model)\n",
    "\n",
    "layer_2_saelayer = {layer: layer_idx for layer_idx, layer in enumerate(main_layers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fec1b-19e6-4b26-830e-4cc696e7d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing protein: 2B61A\n",
      "Sequence length: 377\n",
      "Segment 1: 177-188\n",
      "Segment 2: 311-322\n",
      "Clean flank size: 44\n",
      "Clean sequence contact recovery: 0.5738\n",
      "Corrupted flank size: 43\n",
      "Corrupted sequence contact recovery: 0.0279\n"
     ]
    }
   ],
   "source": [
    "# Load sequence data and define protein parameters\n",
    "with open('../data/full_seq_dict.json', \"r\") as json_file:\n",
    "    seq_dict = json.load(json_file)\n",
    "\n",
    "# Define protein-specific parameters\n",
    "sse_dict = {\"2B61A\": [[182, 316]], \"1PVGA\": [[101, 202]]}\n",
    "fl_dict = {\"2B61A\": [44, 43], \"1PVGA\": [65, 63]}\n",
    "\n",
    "# Choose protein for analysis\n",
    "protein = \"2B61A\"\n",
    "seq = seq_dict[protein]\n",
    "position = sse_dict[protein][0]\n",
    "\n",
    "# Define segment boundaries\n",
    "ss1_start = position[0] - 5 \n",
    "ss1_end = position[0] + 5 + 1 \n",
    "ss2_start = position[1] - 5 \n",
    "ss2_end = position[1] + 5 + 1 \n",
    "\n",
    "print(f\"Analyzing protein: {protein}\")\n",
    "print(f\"Sequence length: {len(seq)}\")\n",
    "print(f\"Segment 1: {ss1_start}-{ss1_end}\")\n",
    "print(f\"Segment 2: {ss2_start}-{ss2_end}\")\n",
    "\n",
    "# Prepare full sequence and get baseline contact predictions\n",
    "full_seq_L = [(1, seq)]\n",
    "_, _, batch_tokens_BL = batch_converter(full_seq_L)\n",
    "batch_tokens_BL = batch_tokens_BL.to(device)\n",
    "batch_mask_BL = (batch_tokens_BL != esm2_alphabet.padding_idx).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_seq_contact_LL = esm_transformer.predict_contacts(batch_tokens_BL, batch_mask_BL)[0]\n",
    "\n",
    "# Prepare clean sequence (with optimal flanks)\n",
    "clean_fl = fl_dict[protein][0]\n",
    "L = len(seq)\n",
    "left_start = max(0, ss1_start - clean_fl)\n",
    "left_end = ss1_start\n",
    "right_start = ss2_end\n",
    "right_end = min(L, ss2_end + clean_fl)\n",
    "unmask_left_idxs = list(range(left_start, left_end))\n",
    "unmask_right_idxs = list(range(right_start, right_end))\n",
    "\n",
    "clean_seq_L = mask_flanks_segment(seq, ss1_start, ss1_end, ss2_start, ss2_end, unmask_left_idxs, unmask_right_idxs)\n",
    "_, _, clean_batch_tokens_BL = batch_converter([(1, clean_seq_L)])\n",
    "clean_batch_tokens_BL = clean_batch_tokens_BL.to(device)\n",
    "clean_batch_mask_BL = (clean_batch_tokens_BL != esm2_alphabet.padding_idx).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    clean_seq_contact_LL = esm_transformer.predict_contacts(clean_batch_tokens_BL, clean_batch_mask_BL)[0]\n",
    "\n",
    "print(f\"Clean flank size: {clean_fl}\")\n",
    "print(f\"Clean sequence contact recovery: {patching_metric(clean_seq_contact_LL, full_seq_contact_LL, ss1_start, ss1_end, ss2_start, ss2_end):.4f}\")\n",
    "\n",
    "# Prepare corrupted sequence (with suboptimal flanks)\n",
    "corr_fl = fl_dict[protein][1]\n",
    "left_start = max(0, ss1_start - corr_fl)\n",
    "left_end = ss1_start\n",
    "right_start = ss2_end\n",
    "right_end = min(L, ss2_end + corr_fl)\n",
    "unmask_left_idxs = list(range(left_start, left_end))\n",
    "unmask_right_idxs = list(range(right_start, right_end))\n",
    "\n",
    "corr_seq_L = mask_flanks_segment(seq, ss1_start, ss1_end, ss2_start, ss2_end, unmask_left_idxs, unmask_right_idxs)\n",
    "_, _, corr_batch_tokens_BL = batch_converter([(1, corr_seq_L)])\n",
    "corr_batch_tokens_BL = corr_batch_tokens_BL.to(device)\n",
    "corr_batch_mask_BL = (corr_batch_tokens_BL != esm2_alphabet.padding_idx).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    corr_seq_contact_LL = esm_transformer.predict_contacts(corr_batch_tokens_BL, corr_batch_mask_BL)[0]\n",
    "\n",
    "print(f\"Corrupted flank size: {corr_fl}\")\n",
    "print(f\"Corrupted sequence contact recovery: {patching_metric(corr_seq_contact_LL, full_seq_contact_LL, ss1_start, ss1_end, ss2_start, ss2_end):.4f}\")\n",
    "\n",
    "# Create patching metric function\n",
    "_patching_metric = partial(\n",
    "    patching_metric,\n",
    "    orig_contact=full_seq_contact_LL,\n",
    "    ss1_start=ss1_start,\n",
    "    ss1_end=ss1_end,\n",
    "    ss2_start=ss2_start,\n",
    "    ss2_end=ss2_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cecfa-125c-42fd-a94a-7bf75365945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting causal ranking with integrated gradients...\n",
      "\n",
      "Processing layer 4...\n",
      "Layer 4: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737996101379395\n",
      "ratio: 0.1, score: 0.601131796836853\n",
      "ratio: 0.2, score: 0.4815935492515564\n",
      "ratio: 0.30000000000000004, score: 0.4985087811946869\n",
      "ratio: 0.4, score: 0.3368060886859894\n",
      "ratio: 0.5, score: 0.2868437170982361\n",
      "ratio: 0.6000000000000001, score: 0.24697260558605194\n",
      "ratio: 0.7000000000000001, score: 0.12411289662122726\n",
      "ratio: 0.8, score: 0.10038772225379944\n",
      "ratio: 0.9, score: 0.033265773206949234\n",
      "\n",
      "Processing layer 8...\n",
      "Layer 8: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737998485565186\n",
      "ratio: 0.1, score: 0.5733504891395569\n",
      "ratio: 0.2, score: 0.49743935465812683\n",
      "ratio: 0.30000000000000004, score: 0.4819444417953491\n",
      "ratio: 0.4, score: 0.4560147225856781\n",
      "ratio: 0.5, score: 0.3371899425983429\n",
      "ratio: 0.6000000000000001, score: 0.24517741799354553\n",
      "ratio: 0.7000000000000001, score: 0.17981162667274475\n",
      "ratio: 0.8, score: 0.080412358045578\n",
      "ratio: 0.9, score: 0.035447120666503906\n",
      "\n",
      "Processing layer 12...\n",
      "Layer 12: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5738003253936768\n",
      "ratio: 0.1, score: 0.5235996842384338\n",
      "ratio: 0.2, score: 0.4417552947998047\n",
      "ratio: 0.30000000000000004, score: 0.3823314607143402\n",
      "ratio: 0.4, score: 0.294727087020874\n",
      "ratio: 0.5, score: 0.26331064105033875\n",
      "ratio: 0.6000000000000001, score: 0.21658875048160553\n",
      "ratio: 0.7000000000000001, score: 0.18368004262447357\n",
      "ratio: 0.8, score: 0.14979280531406403\n",
      "ratio: 0.9, score: 0.07239574939012527\n",
      "\n",
      "Processing layer 16...\n",
      "Layer 16: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737996101379395\n",
      "ratio: 0.1, score: 0.5002211332321167\n",
      "ratio: 0.2, score: 0.41480013728141785\n",
      "ratio: 0.30000000000000004, score: 0.34054064750671387\n",
      "ratio: 0.4, score: 0.2831934094429016\n",
      "ratio: 0.5, score: 0.2488962709903717\n",
      "ratio: 0.6000000000000001, score: 0.19235572218894958\n",
      "ratio: 0.7000000000000001, score: 0.12595593929290771\n",
      "ratio: 0.8, score: 0.07274554669857025\n",
      "ratio: 0.9, score: 0.0414709635078907\n",
      "\n",
      "Processing layer 20...\n",
      "Layer 20: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737987756729126\n",
      "ratio: 0.1, score: 0.49862149357795715\n",
      "ratio: 0.2, score: 0.4209131896495819\n",
      "ratio: 0.30000000000000004, score: 0.3457544147968292\n",
      "ratio: 0.4, score: 0.28239086270332336\n",
      "ratio: 0.5, score: 0.22828815877437592\n",
      "ratio: 0.6000000000000001, score: 0.1883174329996109\n",
      "ratio: 0.7000000000000001, score: 0.14421628415584564\n",
      "ratio: 0.8, score: 0.0972367450594902\n",
      "ratio: 0.9, score: 0.049393367022275925\n",
      "\n",
      "Processing layer 24...\n",
      "Layer 24: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737990140914917\n",
      "ratio: 0.1, score: 0.513055682182312\n",
      "ratio: 0.2, score: 0.4529542326927185\n",
      "ratio: 0.30000000000000004, score: 0.3762893080711365\n",
      "ratio: 0.4, score: 0.3144078254699707\n",
      "ratio: 0.5, score: 0.2803628146648407\n",
      "ratio: 0.6000000000000001, score: 0.2380339652299881\n",
      "ratio: 0.7000000000000001, score: 0.1902957707643509\n",
      "ratio: 0.8, score: 0.13582567870616913\n",
      "ratio: 0.9, score: 0.10489924252033234\n",
      "\n",
      "Processing layer 28...\n",
      "Layer 28: Clean contact recovery: 0.5738, Corr contact recovery: 0.0279\n",
      "ratio: 0.0, score: 0.5737990736961365\n",
      "ratio: 0.1, score: 0.5094301700592041\n",
      "ratio: 0.2, score: 0.4794412851333618\n",
      "ratio: 0.30000000000000004, score: 0.4453980326652527\n",
      "ratio: 0.4, score: 0.4043721854686737\n",
      "ratio: 0.5, score: 0.3773147165775299\n",
      "ratio: 0.6000000000000001, score: 0.3507134020328522\n",
      "ratio: 0.7000000000000001, score: 0.33196407556533813\n",
      "ratio: 0.8, score: 0.3076653778553009\n",
      "ratio: 0.9, score: 0.2687968611717224\n",
      "\n",
      "Causal ranking complete!\n",
      "SAE effects shape: torch.Size([7, 379, 4096])\n",
      "Error effects shape: torch.Size([7, 1, 379, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Perform causal ranking for all latent-token pairs across layers\n",
    "print(\"Starting causal ranking with integrated gradients...\")\n",
    "\n",
    "all_effects_sae_ALS = []\n",
    "all_effects_err_ABLF = []\n",
    "\n",
    "for layer_idx in main_layers:\n",
    "    print(f\"\\nProcessing layer {layer_idx}...\")\n",
    "    \n",
    "    sae_model = saes[layer_2_saelayer[layer_idx]]\n",
    "\n",
    "    # Get clean cache and error\n",
    "    hook = SAEHookProt(sae=sae_model, mask_BL=clean_batch_mask_BL, cache_latents=True, layer_is_lm=False, calc_error=True, use_error=True)\n",
    "    handle = esm_transformer.esm.encoder.layer[layer_idx].register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        clean_seq_sae_contact_LL = esm_transformer.predict_contacts(clean_batch_tokens_BL, clean_batch_mask_BL)[0]\n",
    "    cleanup_cuda()\n",
    "    handle.remove()\n",
    "    clean_cache_LS = sae_model.feature_acts\n",
    "    clean_err_cache_BLF = sae_model.error_term\n",
    "    clean_contact_recovery = _patching_metric(clean_seq_sae_contact_LL)\n",
    "\n",
    "    # Get corrupted cache and error\n",
    "    hook = SAEHookProt(sae=sae_model, mask_BL=corr_batch_mask_BL, cache_latents=True, layer_is_lm=False, calc_error=True, use_error=True)\n",
    "    handle = esm_transformer.esm.encoder.layer[layer_idx].register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        corr_seq_sae_contact_LL = esm_transformer.predict_contacts(corr_batch_tokens_BL, corr_batch_mask_BL)[0]\n",
    "    cleanup_cuda()\n",
    "    handle.remove()\n",
    "    corr_cache_LS = sae_model.feature_acts\n",
    "    corr_err_cache_BLF = sae_model.error_term\n",
    "    corr_contact_recovery = _patching_metric(corr_seq_sae_contact_LL)\n",
    "    \n",
    "    print(f\"Layer {layer_idx}: Clean contact recovery: {clean_contact_recovery:.4f}, Corr contact recovery: {corr_contact_recovery:.4f}\")\n",
    "\n",
    "    # Run integrated gradients\n",
    "    effect_sae_LS, effect_err_BLF = integrated_gradients_sae(\n",
    "        esm_transformer,\n",
    "        sae_model,\n",
    "        _patching_metric,\n",
    "        clean_cache_LS.to(device),\n",
    "        corr_cache_LS.to(device),\n",
    "        clean_err_cache_BLF.to(device),\n",
    "        corr_err_cache_BLF.to(device),\n",
    "        batch_tokens=clean_batch_tokens_BL,\n",
    "        batch_mask=clean_batch_mask_BL,\n",
    "        hook_layer=layer_idx,\n",
    "    )\n",
    "\n",
    "    all_effects_sae_ALS.append(effect_sae_LS)\n",
    "    all_effects_err_ABLF.append(effect_err_BLF)\n",
    "\n",
    "# Stack all effects\n",
    "all_effects_sae_ALS = torch.stack(all_effects_sae_ALS)\n",
    "all_effects_err_ABLF = torch.stack(all_effects_err_ABLF)\n",
    "\n",
    "print(f\"\\nCausal ranking complete!\")\n",
    "print(f\"SAE effects shape: {all_effects_sae_ALS.shape}\")\n",
    "print(f\"Error effects shape: {all_effects_err_ABLF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caad52-dc9e-4fd4-ba6e-ae85b0ad1f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating layer-wise caches for performance analysis...\n",
      "Layer 4, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 4, corr score: 0.0279\n",
      "Layer 8, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 8, corr score: 0.0279\n",
      "Layer 12, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 12, corr score: 0.0279\n",
      "Layer 16, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 16, corr score: 0.0279\n",
      "Layer 20, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 20, corr score: 0.0279\n",
      "Layer 24, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 24, corr score: 0.0279\n",
      "Layer 28, clean score: 0.5738\n",
      "torch.Size([379, 4096]) torch.Size([1, 379, 1280])\n",
      "Layer 28, corr score: 0.0279\n",
      "Layer-wise caches created successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating layer-wise caches for performance analysis...\")\n",
    "\n",
    "clean_layer_caches = {}\n",
    "corr_layer_caches = {}\n",
    "clean_layer_errors = {}\n",
    "corr_layer_errors = {}\n",
    "\n",
    "for layer_idx in main_layers:\n",
    "    sae_model = saes[layer_2_saelayer[layer_idx]]\n",
    "    \n",
    "    # Clean caches\n",
    "    hook = SAEHookProt(sae=sae_model, mask_BL=clean_batch_mask_BL, cache_latents=True, \n",
    "                       layer_is_lm=False, calc_error=True, use_error=True)\n",
    "    handle = esm_transformer.esm.encoder.layer[layer_idx].register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        clean_seq_sae_contact_LL = esm_transformer.predict_contacts(clean_batch_tokens_BL, clean_batch_mask_BL)[0]\n",
    "    cleanup_cuda()\n",
    "    handle.remove()\n",
    "    print(f\"Layer {layer_idx}, clean score: {_patching_metric(clean_seq_sae_contact_LL):.4f}\")\n",
    "    clean_layer_caches[layer_idx] = sae_model.feature_acts\n",
    "    clean_layer_errors[layer_idx] = sae_model.error_term\n",
    "    # print shapes\n",
    "    print(clean_layer_caches[layer_idx].shape, clean_layer_errors[layer_idx].shape)\n",
    "\n",
    "    # Corrupted caches\n",
    "    hook = SAEHookProt(sae=sae_model, mask_BL=corr_batch_mask_BL, cache_latents=True, \n",
    "                       layer_is_lm=False, calc_error=True, use_error=True)\n",
    "    handle = esm_transformer.esm.encoder.layer[layer_idx].register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        corr_seq_sae_contact_LL = esm_transformer.predict_contacts(corr_batch_tokens_BL, corr_batch_mask_BL)[0]\n",
    "    cleanup_cuda()\n",
    "    handle.remove()\n",
    "    print(f\"Layer {layer_idx}, corr score: {_patching_metric(corr_seq_sae_contact_LL):.4f}\")\n",
    "    corr_layer_caches[layer_idx] = sae_model.feature_acts\n",
    "    corr_layer_errors[layer_idx] = sae_model.error_term\n",
    "\n",
    "print(\"Layer-wise caches created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8558628-c0fe-4482-abe7-9d0653956724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "up_layer = 4\n",
    "down_layer = 8\n",
    "print(layer_2_saelayer[up_layer], layer_2_saelayer[down_layer])\n",
    "up_sae = saes[layer_2_saelayer[up_layer]]\n",
    "down_sae = saes[layer_2_saelayer[down_layer]]\n",
    "\n",
    "up_effects = all_effects_sae_ALS[layer_2_saelayer[up_layer]]\n",
    "down_effects = all_effects_sae_ALS[layer_2_saelayer[down_layer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61eb59-78c9-4fe9-a438-96b67d672dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m top_rank_vals_up, top_idx_up \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(up_effect_flat, k\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m top_rank_vals_down, top_idx_down \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(down_effect_flat, k\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m row_indices_up \u001b[39m=\u001b[39m top_idx_up \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m S\n\u001b[1;32m     12\u001b[0m col_indices_up \u001b[39m=\u001b[39m top_idx_up \u001b[39m%\u001b[39m S\n\u001b[1;32m     14\u001b[0m row_indices_down \u001b[39m=\u001b[39m top_idx_down \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m S\n",
      "\u001b[0;31mNameError\u001b[0m: name 'S' is not defined"
     ]
    }
   ],
   "source": [
    "# getting the top 50 features for each layer\n",
    "\n",
    "up_effect_flat = up_effects.reshape(-1)\n",
    "down_effect_flat = down_effects.reshape(-1)\n",
    "\n",
    "top_rank_vals_up, top_idx_up = torch.topk(up_effect_flat, k=50, largest=False, sorted=True)\n",
    "top_rank_vals_down, top_idx_down = torch.topk(down_effect_flat, k=50, largest=False, sorted=True)\n",
    "\n",
    "row_indices_up = top_idx_up // S\n",
    "col_indices_up = top_idx_up % S\n",
    "\n",
    "row_indices_down = top_idx_down // S\n",
    "col_indices_down = top_idx_down % S\n",
    "\n",
    "# print the top 5 for up and down\n",
    "print(top_rank_vals_up[:5], top_idx_up[:5])\n",
    "print(top_rank_vals_down[:5], top_idx_down[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028c1ec-76f2-42a1-ba22-3438f149a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0259, -0.0236, -0.0187, -0.0187, -0.0174]) tensor([1460619, 1461827, 1459139, 1503572, 1503469])\n",
      "tensor([-0.0173, -0.0173, -0.0160, -0.0133, -0.0133]) tensor([1294824,  748149, 1297111, 1296822,  748856])\n"
     ]
    }
   ],
   "source": [
    "# getting the top 50 features for each layer\n",
    "\n",
    "up_effect_flat = up_effects.reshape(-1)\n",
    "down_effect_flat = down_effects.reshape(-1)\n",
    "\n",
    "top_rank_vals_up, top_idx_up = torch.topk(up_effect_flat, k=50, largest=False, sorted=True)\n",
    "top_rank_vals_down, top_idx_down = torch.topk(down_effect_flat, k=50, largest=False, sorted=True)\n",
    "\n",
    "L, S = up_effects.shape\n",
    "\n",
    "row_indices_up = top_idx_up // S\n",
    "col_indices_up = top_idx_up % S\n",
    "\n",
    "row_indices_down = top_idx_down // S\n",
    "col_indices_down = top_idx_down % S\n",
    "\n",
    "# print the top 5 for up and down\n",
    "print(top_rank_vals_up[:5], top_idx_up[:5])\n",
    "print(top_rank_vals_down[:5], top_idx_down[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb29e9-3649-450e-a789-e75335b8f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up: -0.025851, 356, 2443\n",
      "Down: -0.017311, 316, 488\n",
      "Up: -0.023650, 356, 3651\n",
      "Down: -0.017272, 182, 2677\n",
      "Up: -0.018743, 356, 963\n",
      "Down: -0.015968, 316, 2775\n",
      "Up: -0.018701, 367, 340\n",
      "Down: -0.013317, 316, 2486\n",
      "Up: -0.017374, 367, 237\n",
      "Down: -0.013286, 182, 3384\n"
     ]
    }
   ],
   "source": [
    "# getting the top 50 features for each layer\n",
    "\n",
    "up_effect_flat = up_effects.reshape(-1)\n",
    "down_effect_flat = down_effects.reshape(-1)\n",
    "\n",
    "top_rank_vals_up, top_idx_up = torch.topk(up_effect_flat, k=50, largest=False, sorted=True)\n",
    "top_rank_vals_down, top_idx_down = torch.topk(down_effect_flat, k=50, largest=False, sorted=True)\n",
    "\n",
    "L, S = up_effects.shape\n",
    "\n",
    "row_indices_up = top_idx_up // S\n",
    "col_indices_up = top_idx_up % S\n",
    "\n",
    "row_indices_down = top_idx_down // S\n",
    "col_indices_down = top_idx_down % S\n",
    "\n",
    "# print the top 5 for up and down\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Up: {top_rank_vals_up[i]:.6f}, {row_indices_up[i]}, {col_indices_up[i]}\")\n",
    "    print(f\"Down: {top_rank_vals_down[i]:.6f}, {row_indices_down[i]}, {col_indices_down[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5694bba-cfad-470b-a19a-75dc7c85e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up: -0.025851, 356, 2443, -0.025851\n",
      "Up: -0.023650, 356, 3651, -0.023650\n",
      "Up: -0.018743, 356, 963, -0.018743\n",
      "Up: -0.018701, 367, 340, -0.018701\n",
      "Up: -0.017374, 367, 237, -0.017374\n",
      "Down: -0.017311, 316, 488, -0.017311\n",
      "Down: -0.017272, 182, 2677, -0.017272\n",
      "Down: -0.015968, 316, 2775, -0.015968\n",
      "Down: -0.013317, 316, 2486, -0.013317\n",
      "Down: -0.013286, 182, 3384, -0.013286\n"
     ]
    }
   ],
   "source": [
    "# getting the top 50 features for each layer\n",
    "\n",
    "up_effect_flat = up_effects.reshape(-1)\n",
    "down_effect_flat = down_effects.reshape(-1)\n",
    "\n",
    "top_rank_vals_up, top_idx_up = torch.topk(up_effect_flat, k=50, largest=False, sorted=True)\n",
    "top_rank_vals_down, top_idx_down = torch.topk(down_effect_flat, k=50, largest=False, sorted=True)\n",
    "\n",
    "L, S = up_effects.shape\n",
    "\n",
    "row_indices_up = top_idx_up // S\n",
    "col_indices_up = top_idx_up % S\n",
    "\n",
    "row_indices_down = top_idx_down // S\n",
    "col_indices_down = top_idx_down % S\n",
    "\n",
    "# print the top 5 for up and down\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Up: {top_rank_vals_up[i]:.6f}, {row_indices_up[i]}, {col_indices_up[i]}, {up_effects[row_indices_up[i], col_indices_up[i]]:.6f}\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Down: {top_rank_vals_down[i]:.6f}, {row_indices_down[i]}, {col_indices_down[i]}, {down_effects[row_indices_down[i], col_indices_down[i]]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bbb9b-c12e-4eea-821d-df0c52abea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(2443), tensor(3651), tensor(963), tensor(340), tensor(237), tensor(1474), tensor(794), tensor(443), tensor(2340), tensor(3788), tensor(3701), tensor(2311), tensor(2277), tensor(3153), tensor(798), tensor(3634), tensor(1682), tensor(1690), tensor(3764), tensor(3326), tensor(1096), tensor(3351), tensor(1712), tensor(181), tensor(3177), tensor(3832), tensor(1807), tensor(3612), tensor(495), tensor(1297), tensor(1807), tensor(816), tensor(1890), tensor(1474), tensor(992), tensor(72), tensor(1370), tensor(481), tensor(1297), tensor(2956), tensor(2850), tensor(816), tensor(3343), tensor(379), tensor(2672), tensor(897), tensor(3480), tensor(1297), tensor(423), tensor(1890)] [tensor(488), tensor(2677), tensor(2775), tensor(2486), tensor(3384), tensor(2775), tensor(431), tensor(1575), tensor(2166), tensor(3921), tensor(3319), tensor(3092), tensor(3381), tensor(2693), tensor(1244), tensor(2380), tensor(1489), tensor(431), tensor(3384), tensor(3102), tensor(576), tensor(1815), tensor(2662), tensor(3864), tensor(2524), tensor(1835), tensor(545), tensor(3642), tensor(4083), tensor(1591), tensor(2041), tensor(2862), tensor(3682), tensor(3997), tensor(2209), tensor(1605), tensor(1233), tensor(3384), tensor(1815), tensor(3384), tensor(2576), tensor(1586), tensor(4042), tensor(2675), tensor(3921), tensor(3716), tensor(312), tensor(3642), tensor(2594), tensor(3368)]\n"
     ]
    }
   ],
   "source": [
    "up_feats = [col_indices_up[i] for i in range(len(col_indices_up))]\n",
    "down_feats = [col_indices_down[i] for i in range(len(col_indices_down))]\n",
    "\n",
    "\n",
    "print(up_feats, down_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f8ac2-b556-4ad9-8148-b4849a897085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2443, 3651, 963, 340, 237, 1474, 794, 443, 2340, 3788, 3701, 2311, 2277, 3153, 798, 3634, 1682, 1690, 3764, 3326, 1096, 3351, 1712, 181, 3177, 3832, 1807, 3612, 495, 1297, 1807, 816, 1890, 1474, 992, 72, 1370, 481, 1297, 2956, 2850, 816, 3343, 379, 2672, 897, 3480, 1297, 423, 1890] [488, 2677, 2775, 2486, 3384, 2775, 431, 1575, 2166, 3921, 3319, 3092, 3381, 2693, 1244, 2380, 1489, 431, 3384, 3102, 576, 1815, 2662, 3864, 2524, 1835, 545, 3642, 4083, 1591, 2041, 2862, 3682, 3997, 2209, 1605, 1233, 3384, 1815, 3384, 2576, 1586, 4042, 2675, 3921, 3716, 312, 3642, 2594, 3368]\n"
     ]
    }
   ],
   "source": [
    "up_feats = [col_indices_up[i].item() for i in range(len(col_indices_up))]\n",
    "down_feats = [col_indices_down[i].item() for i in range(len(col_indices_down))]\n",
    "\n",
    "\n",
    "print(up_feats, down_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15530577-6f49-470f-8678-0dac59dcbeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2443, 3651, 963, 340, 237, 1474, 794, 443, 2340, 3788, 3701, 2311, 2277, 3153, 798, 3634, 1682, 1690, 3764, 3326, 1096, 3351, 1712, 181, 3177, 3832, 1807, 3612, 495, 1297, 1807, 816, 1890, 1474, 992, 72, 1370, 481, 1297, 2956, 2850, 816, 3343, 379, 2672, 897, 3480, 1297, 423, 1890] [488, 2677, 2775, 2486, 3384, 2775, 431, 1575, 2166, 3921, 3319, 3092, 3381, 2693, 1244, 2380, 1489, 431, 3384, 3102, 576, 1815, 2662, 3864, 2524, 1835, 545, 3642, 4083, 1591, 2041, 2862, 3682, 3997, 2209, 1605, 1233, 3384, 1815, 3384, 2576, 1586, 4042, 2675, 3921, 3716, 312, 3642, 2594, 3368]\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "up_feats = [col_indices_up[i].item() for i in range(len(col_indices_up))]\n",
    "down_feats = [col_indices_down[i].item() for i in range(len(col_indices_down))]\n",
    "\n",
    "print(up_feats, down_feats)\n",
    "print(len(up_feats), len(down_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a6bc0-a68b-4995-bb0f-ef26348a8469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor(237), tensor(963), tensor(340), tensor(2340), tensor(3326), tensor(3177), tensor(481), tensor(3343), tensor(379), tensor(1712), tensor(2850), tensor(1890), tensor(3788), tensor(2311), tensor(1807), tensor(3480), tensor(3764), tensor(1096), tensor(3351), tensor(181), tensor(816), tensor(1370), tensor(816), tensor(3651), tensor(3701), tensor(1682), tensor(3612), tensor(72), tensor(443), tensor(1690), tensor(1297), tensor(992), tensor(1297), tensor(897), tensor(423), tensor(3634), tensor(3832), tensor(495), tensor(1474), tensor(2956), tensor(2672), tensor(2443), tensor(1474), tensor(794), tensor(2277), tensor(3153), tensor(798), tensor(1807), tensor(1890), tensor(1297)} {tensor(2677), tensor(431), tensor(2693), tensor(2662), tensor(2524), tensor(3997), tensor(3921), tensor(3092), tensor(1815), tensor(2041), tensor(1815), tensor(3368), tensor(488), tensor(2486), tensor(431), tensor(3384), tensor(1835), tensor(1605), tensor(1586), tensor(312), tensor(2775), tensor(3921), tensor(1244), tensor(576), tensor(545), tensor(3682), tensor(2576), tensor(4042), tensor(2775), tensor(1489), tensor(3864), tensor(1591), tensor(3384), tensor(3642), tensor(3384), tensor(3381), tensor(3642), tensor(2209), tensor(3716), tensor(1575), tensor(2166), tensor(3319), tensor(3102), tensor(2862), tensor(2675), tensor(2380), tensor(4083), tensor(1233), tensor(3384), tensor(2594)}\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "up_feats = set(col_indices_up)\n",
    "down_feats = set(col_indices_down)\n",
    "# up_feats = [col_indices_up[i].item() for i in range(len(col_indices_up))]\n",
    "# down_feats = [col_indices_down[i].item() for i in range(len(col_indices_down))]\n",
    "\n",
    "print(up_feats, down_feats)\n",
    "print(len(up_feats), len(down_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632daa2-b06b-4517-97d5-7544025cbc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 42\n",
      "{897, 2311, 2443, 2956, 1807, 3343, 1297, 1682, 3351, 3480, 1690, 794, 3612, 798, 2850, 2340, 423, 1712, 816, 3634, 3764, 181, 443, 1474, 3651, 963, 1096, 72, 3788, 3153, 340, 1370, 992, 481, 1890, 2277, 3177, 237, 495, 2672, 3701, 3832, 379, 3326} {3716, 2693, 2576, 3092, 1815, 3864, 3997, 3102, 545, 2209, 2594, 1575, 3368, 1835, 2862, 431, 1586, 3381, 2486, 1591, 3384, 312, 3642, 576, 1605, 4042, 2380, 3921, 1489, 1233, 2775, 1244, 2524, 3682, 2662, 488, 4083, 2675, 2677, 2166, 3319, 2041}\n"
     ]
    }
   ],
   "source": [
    "up_feats = set([col_indices_up[i].item() for i in range(len(col_indices_up))])\n",
    "down_feats = set([col_indices_down[i].item() for i in range(len(col_indices_down))])\n",
    "# up_feats = [col_indices_up[i].item() for i in range(len(col_indices_up))]\n",
    "# down_feats = [col_indices_down[i].item() for i in range(len(col_indices_down))]\n",
    "\n",
    "print(len(up_feats), len(down_feats))\n",
    "print(up_feats, down_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d472fe-5a3a-4f73-9c7d-767468279f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: tensor([[-0.1607,  0.1270,  1.4314,  ..., -0.3031, -0.1435,  0.2459],\n",
       "         [ 0.0055,  0.0566,  0.4922,  ..., -0.1025, -0.1160,  0.3915],\n",
       "         [ 0.0207,  0.0668,  0.3704,  ..., -0.1236, -0.1527,  0.4087],\n",
       "         ...,\n",
       "         [ 0.4824, -0.1890,  0.3038,  ..., -0.0845, -0.0922,  0.4022],\n",
       "         [ 0.0837,  0.0077,  0.1362,  ..., -0.2109, -0.0207,  0.4601],\n",
       "         [-0.5801, -0.0170,  0.1643,  ..., -0.2089, -0.3712,  0.2665]]),\n",
       " 8: tensor([[-1.0235,  0.8383, -2.1761,  ..., -2.2417, -1.9606,  0.0067],\n",
       "         [-2.4729, -2.3292, -2.8839,  ..., -3.9402, -0.5738, -0.0505],\n",
       "         [-2.4464, -2.3414, -2.9118,  ..., -3.6948, -0.4485, -0.1777],\n",
       "         ...,\n",
       "         [-1.4288, -1.3229,  0.0797,  ..., -4.1169,  0.0491,  0.5928],\n",
       "         [-1.3160, -0.2827, -0.7971,  ..., -3.3593, -1.3171,  0.4319],\n",
       "         [-1.0548,  1.0433, -1.2201,  ..., -1.7649, -0.6998, -0.3574]]),\n",
       " 12: tensor([[-1.3224, -1.0477, -1.4013,  ..., -1.3675, -0.3735,  0.5314],\n",
       "         [-2.7802, -0.9256, -1.6140,  ..., -1.6863, -0.4860,  0.0414],\n",
       "         [-2.7977, -1.0461, -1.3725,  ..., -1.4154, -0.9021,  0.0851],\n",
       "         ...,\n",
       "         [-1.6946, -1.9392, -0.7309,  ..., -1.8281, -0.0739,  1.7817],\n",
       "         [-1.8636, -0.7352, -1.2224,  ..., -2.1043, -0.0043,  1.0765],\n",
       "         [-1.2330, -2.0073, -1.1786,  ..., -2.1571, -0.8133, -0.5518]]),\n",
       " 16: tensor([[-5.0841, -0.7520, -0.2559,  ..., -1.4328, -0.9130,  0.2537],\n",
       "         [-5.4643, -2.4542, -0.9655,  ..., -1.5451, -0.1369, -1.6989],\n",
       "         [-5.6337, -2.8710, -1.1065,  ..., -1.6639, -0.8031, -1.3892],\n",
       "         ...,\n",
       "         [-4.6855, -2.0455, -0.3183,  ..., -2.2978,  0.4024, -0.7566],\n",
       "         [-4.5226, -2.0349, -1.0437,  ..., -1.8343,  1.7037, -1.3168],\n",
       "         [-3.4531, -0.9449, -0.7448,  ..., -1.7700, -1.0437, -0.4610]]),\n",
       " 20: tensor([[-0.5000,  0.0291, -2.0330,  ...,  0.0262, -1.0988, -1.0798],\n",
       "         [-1.1976, -1.8413, -3.1468,  ..., -1.3394, -1.3708, -0.8229],\n",
       "         [-1.4269, -2.0287, -3.0386,  ..., -2.1131, -1.9975, -0.8171],\n",
       "         ...,\n",
       "         [-0.6774, -1.6008, -2.1179,  ..., -1.1963, -2.2543, -1.1102],\n",
       "         [-0.4331, -0.7539, -2.5757,  ..., -0.6232, -2.4312, -0.8932],\n",
       "         [-0.1809,  0.0616, -1.8819,  ..., -0.8575, -1.4265, -1.3061]]),\n",
       " 24: tensor([[-1.9181, -0.3166, -0.4046,  ..., -1.1731, -1.0259, -1.2237],\n",
       "         [-1.5284, -1.5037, -0.0780,  ..., -3.2610, -0.7117, -3.9152],\n",
       "         [-1.3768, -1.3401,  0.0080,  ..., -4.2135, -0.4378, -3.3817],\n",
       "         ...,\n",
       "         [-1.5236, -1.1331, -0.9463,  ..., -3.5393, -1.3873, -3.5027],\n",
       "         [-1.3264, -0.1323, -0.2813,  ..., -2.1561, -1.1640, -4.4452],\n",
       "         [-1.9249, -0.5695, -0.7433,  ..., -0.7402, -1.3249, -1.5112]]),\n",
       " 28: tensor([[-1.2361, -0.4978, -0.2296,  ..., -1.2668, -0.3691, -0.2292],\n",
       "         [-1.9217, -1.3189, -4.7777,  ..., -3.3627, -0.9156, -1.3943],\n",
       "         [-0.9450, -1.6394, -4.4298,  ..., -2.7534, -2.0517, -1.0562],\n",
       "         ...,\n",
       "         [-2.9858, -1.0513, -4.3401,  ..., -2.6208, -1.1512, -1.1390],\n",
       "         [-3.2840, -1.4467, -1.9662,  ..., -2.3459, -0.7225, -1.0454],\n",
       "         [-1.2463, -0.4646, -0.0714,  ..., -0.7245, -0.3767, -0.8239]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_layer_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718e8cd-f3ef-49ad-bd89-734941e40287",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_base = clean_layer_caches[up_layer].detach().clone().to(device).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1c24d-0911-4436-bc5c-53ca398198f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_base = clean_layer_caches[up_layer].detach().clone().to(device).requires_grad_()\n",
    "up_base_corr = corr_layer_caches[up_layer].detach().clone().to(device).requires_grad_()\n",
    "patch_mask_LS = torch.ones((L, S), dtype=torch.bool, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a48a3-8abe-4c16-83ad-0232f017bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_fn() -> torch.Tensor:    # returns [B, L, S_down]\n",
    "\n",
    "    # up hook that puts patch activations \n",
    "    up_sae.mean_error = up_error\n",
    "    up_hook = SAEHookProt(sae=up_sae, mask_BL=clean_batch_mask_BL, patch_mask_BLS=patch_mask_LS, patch_value=up_base, use_mean_error=True)\n",
    "\n",
    "    # down hook that records downstream activations\n",
    "    down_sae.mean_error = down_error\n",
    "    down_hook = SAEHookProt(sae=down_sae, mask_BL=clean_batch_mask_BL, cache_latents=True, layer_is_lm=False, calc_error=True, use_error=True, no_detach=True)\n",
    "\n",
    "    # register the hooks\n",
    "    handle_up = esm_transformer.esm.encoder.layer[up_layer].register_forward_hook(up_hook)\n",
    "    handle_down = esm_transformer.esm.encoder.layer[down_layer].register_forward_hook(down_hook)\n",
    "\n",
    "    # run the forward pass\n",
    "    # _, saes_out = run_with_saes( # TODO add the hook for each 1. intervening on upstream, 2. recording downstream\n",
    "    #     model,\n",
    "    #     base_saes,\n",
    "    #     token_list,\n",
    "    #     calc_error=False,\n",
    "    #     use_error=False,\n",
    "    #     fake_activations=(upstream_sae.cfg.hook_layer, up_base),  # TODO saes dont have cfg\n",
    "    #     use_mean_error=use_mean_error,\n",
    "    #     cache_sae_activations=True,   # we need the graph intact\n",
    "    #     no_detach=True,\n",
    "    # )\n",
    "    # feats = saes_out[downstream_sae.cfg.hook_layer].feature_acts\n",
    "    _ = esm_transformer.predict_contacts(clean_batch_tokens_BL, clean_batch_mask_BL)[0]\n",
    "    handle_up.remove()\n",
    "    handle_down.remove()\n",
    "    feats = down_sae.feature_acts\n",
    "    if not feats.requires_grad:\n",
    "        raise RuntimeError(\n",
    "            \"[edge-attr-vjp] downstream activations are detached; \"\n",
    "            \"remove `.detach()` inside your SAE hook or clone with \"\n",
    "            \"`.requires_grad_()` earlier in the graph.\"\n",
    "        )\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b5c8a-77a9-44cf-855b-f9b7dd397788",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'up_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 3. Single forward pass (re-used for every downstream feature)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m down_base \u001b[39m=\u001b[39m _forward_fn()             \u001b[39m# [B,L,S_down]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m down_grad \u001b[39m=\u001b[39m down_effects\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Container: (down_idx, up_idx) → list[val]\u001b[39;00m\n",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_fn\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:    \u001b[39m# returns [B, L, S_down]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[39m# up hook that puts patch activations \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     up_sae\u001b[39m.\u001b[39mmean_error \u001b[39m=\u001b[39m up_error\n\u001b[1;32m      7\u001b[0m     up_hook \u001b[39m=\u001b[39m SAEHookProt(sae\u001b[39m=\u001b[39mup_sae, mask_BL\u001b[39m=\u001b[39mclean_batch_mask_BL, patch_mask_BLS\u001b[39m=\u001b[39mpatch_mask_LS, patch_value\u001b[39m=\u001b[39mup_base, use_mean_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     \u001b[39m# down hook that records downstream activations\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'up_error' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 3. Single forward pass (re-used for every downstream feature)\n",
    "# ----------------------------------------------------------------------\n",
    "down_base = _forward_fn()             # [B,L,S_down]\n",
    "down_grad = down_effects.to(device)\n",
    "\n",
    "# Container: (down_idx, up_idx) → list[val]\n",
    "bucket: Dict[Tuple[int, int], List[torch.Tensor]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d4bb2-92d9-42ca-9738-6e13ea030b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_base = clean_layer_caches[up_layer].detach().clone().to(device).requires_grad_()\n",
    "up_base_corr = corr_layer_caches[up_layer].detach().clone().to(device).requires_grad_()\n",
    "patch_mask_LS = torch.ones((L, S), dtype=torch.bool, device=device)\n",
    "up_error = clean_layer_errors[up_layer].to(device)\n",
    "down_error = clean_layer_errors[down_layer].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a4b58-2df1-44bd-913e-0080b15bee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_fn() -> torch.Tensor:    # returns [B, L, S_down]\n",
    "\n",
    "    # up hook that puts patch activations \n",
    "    up_sae.mean_error = up_error\n",
    "    up_hook = SAEHookProt(sae=up_sae, mask_BL=clean_batch_mask_BL, patch_mask_BLS=patch_mask_LS, patch_value=up_base, use_mean_error=True)\n",
    "\n",
    "    # down hook that records downstream activations\n",
    "    down_sae.mean_error = down_error\n",
    "    down_hook = SAEHookProt(sae=down_sae, mask_BL=clean_batch_mask_BL, cache_latents=True, layer_is_lm=False, calc_error=True, use_error=True, no_detach=True)\n",
    "\n",
    "    # register the hooks\n",
    "    handle_up = esm_transformer.esm.encoder.layer[up_layer].register_forward_hook(up_hook)\n",
    "    handle_down = esm_transformer.esm.encoder.layer[down_layer].register_forward_hook(down_hook)\n",
    "\n",
    "    # run the forward pass\n",
    "    # _, saes_out = run_with_saes( # TODO add the hook for each 1. intervening on upstream, 2. recording downstream\n",
    "    #     model,\n",
    "    #     base_saes,\n",
    "    #     token_list,\n",
    "    #     calc_error=False,\n",
    "    #     use_error=False,\n",
    "    #     fake_activations=(upstream_sae.cfg.hook_layer, up_base),  # TODO saes dont have cfg\n",
    "    #     use_mean_error=use_mean_error,\n",
    "    #     cache_sae_activations=True,   # we need the graph intact\n",
    "    #     no_detach=True,\n",
    "    # )\n",
    "    # feats = saes_out[downstream_sae.cfg.hook_layer].feature_acts\n",
    "    _ = esm_transformer.predict_contacts(clean_batch_tokens_BL, clean_batch_mask_BL)[0]\n",
    "    handle_up.remove()\n",
    "    handle_down.remove()\n",
    "    feats = down_sae.feature_acts\n",
    "    if not feats.requires_grad:\n",
    "        raise RuntimeError(\n",
    "            \"[edge-attr-vjp] downstream activations are detached; \"\n",
    "            \"remove `.detach()` inside your SAE hook or clone with \"\n",
    "            \"`.requires_grad_()` earlier in the graph.\"\n",
    "        )\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69c016-9077-459e-bbeb-9c32d6a22c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m down_grad \u001b[39m=\u001b[39m down_effects\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Container: (down_idx, up_idx) → list[val]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m bucket: Dict[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m], List[torch\u001b[39m.\u001b[39mTensor]] \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 3. Single forward pass (re-used for every downstream feature)\n",
    "# ----------------------------------------------------------------------\n",
    "down_base = _forward_fn()             # [B,L,S_down]\n",
    "down_grad = down_effects.to(device)\n",
    "\n",
    "# Container: (down_idx, up_idx) → list[val]\n",
    "bucket: Dict[Tuple[int, int], List[torch.Tensor]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f51e9-20c2-4aa2-b237-dbfd6e75a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Single forward pass (re-used for every downstream feature)\n",
    "# ----------------------------------------------------------------------\n",
    "down_base = _forward_fn()             # [B,L,S_down]\n",
    "down_grad = down_effects.to(device)\n",
    "\n",
    "# Container: (down_idx, up_idx) → list[val]\n",
    "bucket: Dict[Tuple[int, int], List[torch.Tensor]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e0f7e-30a0-44c7-ae5b-855fd4e1900c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logstats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         bucket\u001b[39m.\u001b[39msetdefault((d_idx, u_idx), [])\u001b[39m.\u001b[39mappend(val\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mif\u001b[39;00m logstats \u001b[39mand\u001b[39;00m (d_idx \u001b[39m==\u001b[39m down_feats[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m d_idx \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     28\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[edge-attr-vjp] processed downstream idx \u001b[39m\u001b[39m{\u001b[39;00md_idx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# 5. Assemble sparse COO tensor\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logstats' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 4. Loop over downstream features (rows of the Jacobian)\n",
    "# ----------------------------------------------------------------------\n",
    "for d_idx in down_feats:\n",
    "    # Select the scalar we will back-prop; optionally weight by loss grad\n",
    "    scalar_field = down_base[..., d_idx]\n",
    "    if down_grad is not None:\n",
    "        scalar_field = scalar_field * down_grad[..., d_idx]\n",
    "    scalar = scalar_field.sum()\n",
    "\n",
    "    # Jᵀ ▽  – gradient w.r.t. *entire* upstream latent tensor\n",
    "    grad_tensor = torch.autograd.grad(\n",
    "        scalar,\n",
    "        up_base,\n",
    "        retain_graph=True,   # keep graph for next d_idx\n",
    "        create_graph=False,  # we only need first-order grads\n",
    "    )[0]                     # shape [B,L,S_up]\n",
    "\n",
    "    # Accumulate entries we care about\n",
    "    for u_idx in up_feats:\n",
    "        val = grad_tensor[..., u_idx].sum()  # Σ_{b,t}\n",
    "        if val.abs() < 1e-6:                 # keep/raise threshold as needed\n",
    "            continue\n",
    "        bucket.setdefault((d_idx, u_idx), []).append(val.detach().cpu())\n",
    "\n",
    "    if logstats and (d_idx == down_feats[0] or d_idx % 10 == 0):\n",
    "        print(f\"[edge-attr-vjp] processed downstream idx {d_idx}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Assemble sparse COO tensor\n",
    "# ----------------------------------------------------------------------\n",
    "if not bucket:\n",
    "    return None\n",
    "\n",
    "idxs, vals = zip(\n",
    "    *[((d, u), torch.stack(v).mean()) for (d, u), v in bucket.items()]\n",
    ")\n",
    "idx_mat = torch.tensor(list(zip(*idxs)), dtype=torch.long)  # [2, N]\n",
    "val_mat = torch.stack(list(vals))                           # [N]\n",
    "\n",
    "edge_tensor = torch.sparse_coo_tensor(\n",
    "    idx_mat,\n",
    "    val_mat,\n",
    "    size=(len(down_feats), len(up_feats)),\n",
    ").coalesce()\n",
    "\n",
    "if logstats:\n",
    "    nnz = edge_tensor._nnz()\n",
    "    print(f\"[edge-attr-vjp] finished – {nnz} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02b0e7-540b-4687-9db5-d0254b41d38a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/work/pi_jensen_umass_edu/jnainani_umass_edu/plm_circuits/notebooks/edge_attr.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         bucket\u001b[39m.\u001b[39msetdefault((d_idx, u_idx), [])\u001b[39m.\u001b[39mappend(val\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mif\u001b[39;00m logstats \u001b[39mand\u001b[39;00m (d_idx \u001b[39m==\u001b[39m down_feats[\u001b[39m0\u001b[39;49m] \u001b[39mor\u001b[39;00m d_idx \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     29\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[edge-attr-vjp] processed downstream idx \u001b[39m\u001b[39m{\u001b[39;00md_idx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# 5. Assemble sparse COO tensor\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "logstats = True\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Loop over downstream features (rows of the Jacobian)\n",
    "# ----------------------------------------------------------------------\n",
    "for d_idx in down_feats:\n",
    "    # Select the scalar we will back-prop; optionally weight by loss grad\n",
    "    scalar_field = down_base[..., d_idx]\n",
    "    if down_grad is not None:\n",
    "        scalar_field = scalar_field * down_grad[..., d_idx]\n",
    "    scalar = scalar_field.sum()\n",
    "\n",
    "    # Jᵀ ▽  – gradient w.r.t. *entire* upstream latent tensor\n",
    "    grad_tensor = torch.autograd.grad(\n",
    "        scalar,\n",
    "        up_base,\n",
    "        retain_graph=True,   # keep graph for next d_idx\n",
    "        create_graph=False,  # we only need first-order grads\n",
    "    )[0]                     # shape [B,L,S_up]\n",
    "\n",
    "    # Accumulate entries we care about\n",
    "    for u_idx in up_feats:\n",
    "        val = grad_tensor[..., u_idx].sum()  # Σ_{b,t}\n",
    "        if val.abs() < 1e-6:                 # keep/raise threshold as needed\n",
    "            continue\n",
    "        bucket.setdefault((d_idx, u_idx), []).append(val.detach().cpu())\n",
    "\n",
    "    if logstats and (d_idx == down_feats[0] or d_idx % 10 == 0):\n",
    "        print(f\"[edge-attr-vjp] processed downstream idx {d_idx}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Assemble sparse COO tensor\n",
    "# ----------------------------------------------------------------------\n",
    "if not bucket:\n",
    "    return None\n",
    "\n",
    "idxs, vals = zip(\n",
    "    *[((d, u), torch.stack(v).mean()) for (d, u), v in bucket.items()]\n",
    ")\n",
    "idx_mat = torch.tensor(list(zip(*idxs)), dtype=torch.long)  # [2, N]\n",
    "val_mat = torch.stack(list(vals))                           # [N]\n",
    "\n",
    "edge_tensor = torch.sparse_coo_tensor(\n",
    "    idx_mat,\n",
    "    val_mat,\n",
    "    size=(len(down_feats), len(up_feats)),\n",
    ").coalesce()\n",
    "\n",
    "if logstats:\n",
    "    nnz = edge_tensor._nnz()\n",
    "    print(f\"[edge-attr-vjp] finished – {nnz} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01837699-c124-4d81-8594-97a9b9957d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[edge-attr-vjp] processed downstream idx 3716\n",
      "[edge-attr-vjp] processed downstream idx 2380\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-27-78655ce22e91>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    return None\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "logstats = True\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Loop over downstream features (rows of the Jacobian)\n",
    "# ----------------------------------------------------------------------\n",
    "for d_idx in down_feats:\n",
    "    # Select the scalar we will back-prop; optionally weight by loss grad\n",
    "    scalar_field = down_base[..., d_idx]\n",
    "    if down_grad is not None:\n",
    "        scalar_field = scalar_field * down_grad[..., d_idx]\n",
    "    scalar = scalar_field.sum()\n",
    "\n",
    "    # Jᵀ ▽  – gradient w.r.t. *entire* upstream latent tensor\n",
    "    grad_tensor = torch.autograd.grad(\n",
    "        scalar,\n",
    "        up_base,\n",
    "        retain_graph=True,   # keep graph for next d_idx\n",
    "        create_graph=False,  # we only need first-order grads\n",
    "    )[0]                     # shape [B,L,S_up]\n",
    "\n",
    "    # Accumulate entries we care about\n",
    "    for u_idx in up_feats:\n",
    "        val = grad_tensor[..., u_idx].sum()  # Σ_{b,t}\n",
    "        if val.abs() < 1e-6:                 # keep/raise threshold as needed\n",
    "            continue\n",
    "        bucket.setdefault((d_idx, u_idx), []).append(val.detach().cpu())\n",
    "\n",
    "    if logstats and (d_idx == list(down_feats)[0] or d_idx % 10 == 0):\n",
    "        print(f\"[edge-attr-vjp] processed downstream idx {d_idx}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Assemble sparse COO tensor\n",
    "# ----------------------------------------------------------------------\n",
    "if not bucket:\n",
    "    return None\n",
    "\n",
    "idxs, vals = zip(\n",
    "    *[((d, u), torch.stack(v).mean()) for (d, u), v in bucket.items()]\n",
    ")\n",
    "idx_mat = torch.tensor(list(zip(*idxs)), dtype=torch.long)  # [2, N]\n",
    "val_mat = torch.stack(list(vals))                           # [N]\n",
    "\n",
    "edge_tensor = torch.sparse_coo_tensor(\n",
    "    idx_mat,\n",
    "    val_mat,\n",
    "    size=(len(down_feats), len(up_feats)),\n",
    ").coalesce()\n",
    "\n",
    "if logstats:\n",
    "    nnz = edge_tensor._nnz()\n",
    "    print(f\"[edge-attr-vjp] finished – {nnz} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6c7f1-b522-4efa-accb-e3ad23d62611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[edge-attr-vjp] processed downstream idx 3716\n",
      "[edge-attr-vjp] processed downstream idx 2380\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-28-a631ec61d6ec>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    return None\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "logstats = True\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Loop over downstream features (rows of the Jacobian)\n",
    "# ----------------------------------------------------------------------\n",
    "for d_idx in down_feats:\n",
    "    # Select the scalar we will back-prop; optionally weight by loss grad\n",
    "    scalar_field = down_base[..., d_idx]\n",
    "    if down_grad is not None:\n",
    "        scalar_field = scalar_field * down_grad[..., d_idx]\n",
    "    scalar = scalar_field.sum()\n",
    "\n",
    "    # Jᵀ ▽  – gradient w.r.t. *entire* upstream latent tensor\n",
    "    grad_tensor = torch.autograd.grad(\n",
    "        scalar,\n",
    "        up_base,\n",
    "        retain_graph=True,   # keep graph for next d_idx\n",
    "        create_graph=False,  # we only need first-order grads\n",
    "    )[0]                     # shape [B,L,S_up]\n",
    "\n",
    "    # Accumulate entries we care about\n",
    "    for u_idx in up_feats:\n",
    "        val = grad_tensor[..., u_idx].sum()  # Σ_{b,t}\n",
    "        if val.abs() < 1e-6:                 # keep/raise threshold as needed\n",
    "            continue\n",
    "        bucket.setdefault((d_idx, u_idx), []).append(val.detach().cpu())\n",
    "\n",
    "    if logstats and (d_idx == list(down_feats)[0] or d_idx % 10 == 0):\n",
    "        print(f\"[edge-attr-vjp] processed downstream idx {d_idx}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Assemble sparse COO tensor\n",
    "# ----------------------------------------------------------------------\n",
    "if not bucket:\n",
    "    print(\"No bucket\")\n",
    "    return None\n",
    "else:\n",
    "    idxs, vals = zip(\n",
    "        *[((d, u), torch.stack(v).mean()) for (d, u), v in bucket.items()]\n",
    "    )\n",
    "    idx_mat = torch.tensor(list(zip(*idxs)), dtype=torch.long)  # [2, N]\n",
    "    val_mat = torch.stack(list(vals))                           # [N]\n",
    "\n",
    "    edge_tensor = torch.sparse_coo_tensor(\n",
    "        idx_mat,\n",
    "        val_mat,\n",
    "        size=(len(down_feats), len(up_feats)),\n",
    "    ).coalesce()\n",
    "\n",
    "    if logstats:\n",
    "        nnz = edge_tensor._nnz()\n",
    "        print(f\"[edge-attr-vjp] finished – {nnz} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273532cb-6e09-434d-ad6e-9cac3a6c1ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[edge-attr-vjp] processed downstream idx 3716\n",
      "[edge-attr-vjp] processed downstream idx 2380\n",
      "[edge-attr-vjp] finished – 1829 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "logstats = True\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Loop over downstream features (rows of the Jacobian)\n",
    "# ----------------------------------------------------------------------\n",
    "for d_idx in down_feats:\n",
    "    # Select the scalar we will back-prop; optionally weight by loss grad\n",
    "    scalar_field = down_base[..., d_idx]\n",
    "    if down_grad is not None:\n",
    "        scalar_field = scalar_field * down_grad[..., d_idx]\n",
    "    scalar = scalar_field.sum()\n",
    "\n",
    "    # Jᵀ ▽  – gradient w.r.t. *entire* upstream latent tensor\n",
    "    grad_tensor = torch.autograd.grad(\n",
    "        scalar,\n",
    "        up_base,\n",
    "        retain_graph=True,   # keep graph for next d_idx\n",
    "        create_graph=False,  # we only need first-order grads\n",
    "    )[0]                     # shape [B,L,S_up]\n",
    "\n",
    "    # Accumulate entries we care about\n",
    "    for u_idx in up_feats:\n",
    "        val = grad_tensor[..., u_idx].sum()  # Σ_{b,t}\n",
    "        if val.abs() < 1e-6:                 # keep/raise threshold as needed\n",
    "            continue\n",
    "        bucket.setdefault((d_idx, u_idx), []).append(val.detach().cpu())\n",
    "\n",
    "    if logstats and (d_idx == list(down_feats)[0] or d_idx % 10 == 0):\n",
    "        print(f\"[edge-attr-vjp] processed downstream idx {d_idx}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Assemble sparse COO tensor\n",
    "# ----------------------------------------------------------------------\n",
    "if not bucket:\n",
    "    print(\"No bucket\")\n",
    "else:\n",
    "    idxs, vals = zip(\n",
    "        *[((d, u), torch.stack(v).mean()) for (d, u), v in bucket.items()]\n",
    "    )\n",
    "    idx_mat = torch.tensor(list(zip(*idxs)), dtype=torch.long)  # [2, N]\n",
    "    val_mat = torch.stack(list(vals))                           # [N]\n",
    "\n",
    "    edge_tensor = torch.sparse_coo_tensor(\n",
    "        idx_mat,\n",
    "        val_mat,\n",
    "        size=(len(down_feats), len(up_feats)),\n",
    "    ).coalesce()\n",
    "\n",
    "    if logstats:\n",
    "        nnz = edge_tensor._nnz()\n",
    "        print(f\"[edge-attr-vjp] finished – {nnz} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934c1bf-3920-4c09-822f-16f888cd6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[ 312,  312,  312,  ..., 4083, 4083, 4083],\n",
       "                       [  72,  237,  340,  ..., 3764, 3788, 3832]]),\n",
       "       values=tensor([-5.4402e-05,  2.7134e-04,  5.2533e-05,  ...,\n",
       "                      -2.9230e-04,  4.0238e-04,  1.0122e-03]),\n",
       "       size=(42, 44), nnz=1829, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0e9a8-9c3b-4d93-98d0-36756f26ea09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.4402e-05,  2.7134e-04,  5.2533e-05,  ..., -2.9230e-04,\n",
       "         4.0238e-04,  1.0122e-03])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_tensor.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645058b-7489-4684-bb38-9aba2af42fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4402e-05,  2.7134e-04,  5.2533e-05,  ..., -2.9230e-04,\n",
      "         4.0238e-04,  1.0122e-03])\n"
     ]
    }
   ],
   "source": [
    "print(edge_tensor.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06477f73-5bda-4baa-a663-241630aecb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4402e-05,  2.7134e-04,  5.2533e-05,  ..., -2.9230e-04,\n",
      "         4.0238e-04,  1.0122e-03])\n"
     ]
    }
   ],
   "source": [
    "print(edge_tensor.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c521842-b59c-42b7-a0e1-06b674ce5ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Edge Tensor Analysis ===\n",
      "Edge tensor shape: torch.Size([42, 44])\n",
      "Number of non-zero entries: 1829\n",
      "\n",
      "Edge connections (upstream -> downstream):\n",
      "==================================================\n",
      "\n",
      "Upstream feature 72:\n",
      "  -> Downstream 431: -0.000430\n",
      "  -> Downstream 1591: -0.000409\n",
      "  -> Downstream 3921: -0.000390\n",
      "  -> Downstream 2677: -0.000303\n",
      "  -> Downstream 3642: 0.000192\n",
      "  -> Downstream 2486: 0.000180\n",
      "  -> Downstream 1575: 0.000171\n",
      "  -> Downstream 488: -0.000155\n",
      "  -> Downstream 2693: -0.000140\n",
      "  -> Downstream 2166: -0.000123\n",
      "  -> Downstream 3381: -0.000121\n",
      "  -> Downstream 2380: -0.000113\n",
      "  -> Downstream 3092: 0.000105\n",
      "  -> Downstream 3716: -0.000103\n",
      "  -> Downstream 2524: -0.000095\n",
      "  -> Downstream 2775: -0.000087\n",
      "  -> Downstream 2041: -0.000080\n",
      "  -> Downstream 2662: -0.000075\n",
      "  -> Downstream 2209: -0.000073\n",
      "  -> Downstream 3682: 0.000068\n",
      "  -> Downstream 3102: 0.000061\n",
      "  -> Downstream 4083: -0.000058\n",
      "  -> Downstream 576: 0.000057\n",
      "  -> Downstream 2675: -0.000057\n",
      "  -> Downstream 312: -0.000054\n",
      "  -> Downstream 1489: -0.000050\n",
      "  -> Downstream 1605: -0.000042\n",
      "  -> Downstream 3319: 0.000038\n",
      "  -> Downstream 1586: 0.000036\n",
      "  -> Downstream 2576: -0.000034\n",
      "  -> Downstream 1244: 0.000032\n",
      "  -> Downstream 1233: -0.000032\n",
      "  -> Downstream 2862: -0.000026\n",
      "  -> Downstream 3384: 0.000026\n",
      "  -> Downstream 3368: -0.000019\n",
      "  -> Downstream 1815: -0.000016\n",
      "  -> Downstream 4042: 0.000014\n",
      "  -> Downstream 3864: 0.000013\n",
      "  -> Downstream 1835: 0.000011\n",
      "  -> Downstream 545: 0.000011\n",
      "  -> Downstream 2594: -0.000010\n",
      "  -> Downstream 3997: -0.000009\n",
      "\n",
      "Upstream feature 181:\n",
      "  -> Downstream 3384: 0.000614\n",
      "  -> Downstream 431: -0.000423\n",
      "  -> Downstream 1591: -0.000188\n",
      "  -> Downstream 488: -0.000184\n",
      "  -> Downstream 2677: -0.000169\n",
      "  -> Downstream 2486: 0.000147\n",
      "  -> Downstream 1815: -0.000146\n",
      "  -> Downstream 3642: 0.000119\n",
      "  -> Downstream 3921: 0.000118\n",
      "  -> Downstream 3092: 0.000117\n",
      "  -> Downstream 1575: 0.000111\n",
      "  -> Downstream 2693: -0.000095\n",
      "  -> Downstream 3716: -0.000068\n",
      "  -> Downstream 2662: -0.000064\n",
      "  -> Downstream 2166: -0.000044\n",
      "  -> Downstream 1244: 0.000043\n",
      "  -> Downstream 576: 0.000041\n",
      "  -> Downstream 2209: -0.000041\n",
      "  -> Downstream 1586: 0.000035\n",
      "  -> Downstream 2862: -0.000035\n",
      "  -> Downstream 1233: -0.000035\n",
      "  -> Downstream 2524: -0.000035\n",
      "  -> Downstream 2041: -0.000033\n",
      "  -> Downstream 3381: -0.000032\n",
      "  -> Downstream 2576: -0.000028\n",
      "  -> Downstream 3864: 0.000028\n",
      "  -> Downstream 545: -0.000028\n",
      "  -> Downstream 1605: -0.000025\n",
      "  -> Downstream 2380: -0.000024\n",
      "  -> Downstream 3319: -0.000023\n",
      "  -> Downstream 4083: 0.000022\n",
      "  -> Downstream 2775: 0.000021\n",
      "  -> Downstream 3102: 0.000021\n",
      "  -> Downstream 2675: -0.000017\n",
      "  -> Downstream 3368: -0.000014\n",
      "  -> Downstream 2594: -0.000011\n",
      "  -> Downstream 3682: 0.000010\n",
      "  -> Downstream 3997: -0.000010\n",
      "  -> Downstream 1835: 0.000009\n",
      "  -> Downstream 4042: 0.000006\n",
      "  -> Downstream 1489: 0.000005\n",
      "\n",
      "Upstream feature 237:\n",
      "  -> Downstream 545: 0.007893\n",
      "  -> Downstream 2775: 0.005616\n",
      "  -> Downstream 2486: -0.002843\n",
      "  -> Downstream 488: 0.002605\n",
      "  -> Downstream 2166: -0.001386\n",
      "  -> Downstream 1575: -0.001350\n",
      "  -> Downstream 3381: 0.001217\n",
      "  -> Downstream 3319: 0.001157\n",
      "  -> Downstream 431: -0.001084\n",
      "  -> Downstream 1489: 0.000833\n",
      "  -> Downstream 1591: 0.000771\n",
      "  -> Downstream 1586: -0.000758\n",
      "  -> Downstream 3716: 0.000714\n",
      "  -> Downstream 2380: -0.000636\n",
      "  -> Downstream 2693: 0.000574\n",
      "  -> Downstream 576: 0.000572\n",
      "  -> Downstream 3921: -0.000567\n",
      "  -> Downstream 3092: -0.000550\n",
      "  -> Downstream 3997: 0.000488\n",
      "  -> Downstream 3368: 0.000403\n",
      "  -> Downstream 4083: 0.000400\n",
      "  -> Downstream 4042: 0.000350\n",
      "  -> Downstream 2675: 0.000322\n",
      "  -> Downstream 2862: 0.000321\n",
      "  -> Downstream 2041: -0.000313\n",
      "  -> Downstream 2524: 0.000299\n",
      "  -> Downstream 312: 0.000271\n",
      "  -> Downstream 2209: 0.000259\n",
      "  -> Downstream 3102: -0.000251\n",
      "  -> Downstream 2662: 0.000236\n",
      "  -> Downstream 1233: -0.000187\n",
      "  -> Downstream 3642: 0.000147\n",
      "  -> Downstream 1605: -0.000141\n",
      "  -> Downstream 3384: -0.000108\n",
      "  -> Downstream 1835: 0.000101\n",
      "  -> Downstream 2576: -0.000095\n",
      "  -> Downstream 2594: -0.000061\n",
      "  -> Downstream 1244: -0.000058\n",
      "  -> Downstream 3682: 0.000048\n",
      "  -> Downstream 3864: 0.000043\n",
      "  -> Downstream 1815: -0.000025\n",
      "\n",
      "Upstream feature 340:\n",
      "  -> Downstream 545: 0.000944\n",
      "  -> Downstream 431: -0.000408\n",
      "  -> Downstream 3384: 0.000375\n",
      "  -> Downstream 2677: -0.000307\n",
      "  -> Downstream 488: -0.000301\n",
      "  -> Downstream 1575: 0.000298\n",
      "  -> Downstream 2486: 0.000263\n",
      "  -> Downstream 3092: 0.000239\n",
      "  -> Downstream 2662: 0.000218\n",
      "  -> Downstream 3381: -0.000213\n",
      "  -> Downstream 2775: 0.000180\n",
      "  -> Downstream 2166: 0.000171\n",
      "  -> Downstream 3642: 0.000163\n",
      "  -> Downstream 1815: -0.000153\n",
      "  -> Downstream 3716: -0.000113\n",
      "  -> Downstream 1605: -0.000103\n",
      "  -> Downstream 2209: -0.000102\n",
      "  -> Downstream 1233: -0.000078\n",
      "  -> Downstream 1489: 0.000077\n",
      "  -> Downstream 1591: 0.000071\n",
      "  -> Downstream 3368: -0.000059\n",
      "  -> Downstream 3682: 0.000057\n",
      "  -> Downstream 3864: -0.000055\n",
      "  -> Downstream 2862: -0.000055\n",
      "  -> Downstream 3997: -0.000053\n",
      "  -> Downstream 312: 0.000053\n",
      "  -> Downstream 2524: -0.000052\n",
      "  -> Downstream 4083: 0.000045\n",
      "  -> Downstream 1835: -0.000044\n",
      "  -> Downstream 3102: -0.000036\n",
      "  -> Downstream 2594: 0.000021\n",
      "  -> Downstream 3319: -0.000018\n",
      "  -> Downstream 576: -0.000018\n",
      "  -> Downstream 2576: 0.000010\n",
      "  -> Downstream 3921: -0.000009\n",
      "  -> Downstream 2693: -0.000009\n",
      "  -> Downstream 2675: 0.000009\n",
      "  -> Downstream 1244: -0.000008\n",
      "  -> Downstream 4042: 0.000006\n",
      "  -> Downstream 1586: 0.000005\n",
      "  -> Downstream 2041: -0.000005\n",
      "  -> Downstream 2380: -0.000004\n",
      "\n",
      "Upstream feature 379:\n",
      "  -> Downstream 3384: 0.002837\n",
      "  -> Downstream 2677: -0.002314\n",
      "  -> Downstream 2380: -0.001058\n",
      "  -> Downstream 1489: -0.000850\n",
      "  -> Downstream 3921: -0.000807\n",
      "  -> Downstream 488: -0.000557\n",
      "  -> Downstream 3381: -0.000512\n",
      "  -> Downstream 431: -0.000497\n",
      "  -> Downstream 2775: -0.000413\n",
      "  -> Downstream 1835: -0.000382\n",
      "  -> Downstream 545: 0.000371\n",
      "  -> Downstream 2662: 0.000363\n",
      "  -> Downstream 3642: -0.000351\n",
      "  -> Downstream 2486: 0.000346\n",
      "  -> Downstream 1575: 0.000345\n",
      "  -> Downstream 3092: 0.000311\n",
      "  -> Downstream 1233: 0.000287\n",
      "  -> Downstream 1244: -0.000209\n",
      "  -> Downstream 2576: 0.000208\n",
      "  -> Downstream 3319: -0.000205\n",
      "  -> Downstream 1591: 0.000190\n",
      "  -> Downstream 312: -0.000188\n",
      "  -> Downstream 2209: -0.000163\n",
      "  -> Downstream 2524: -0.000126\n",
      "  -> Downstream 1815: -0.000104\n",
      "  -> Downstream 3102: -0.000098\n",
      "  -> Downstream 4083: -0.000094\n",
      "  -> Downstream 2862: -0.000090\n",
      "  -> Downstream 1605: -0.000085\n",
      "  -> Downstream 4042: 0.000072\n",
      "  -> Downstream 2166: 0.000068\n",
      "  -> Downstream 1586: -0.000063\n",
      "  -> Downstream 3716: -0.000063\n",
      "  -> Downstream 3368: -0.000062\n",
      "  -> Downstream 2041: 0.000061\n",
      "  -> Downstream 3864: -0.000054\n",
      "  -> Downstream 576: -0.000046\n",
      "  -> Downstream 2594: -0.000043\n",
      "  -> Downstream 3997: 0.000037\n",
      "  -> Downstream 2693: -0.000036\n",
      "  -> Downstream 3682: -0.000021\n",
      "  -> Downstream 2675: 0.000002\n",
      "\n",
      "Upstream feature 423:\n",
      "  -> Downstream 3921: -0.004782\n",
      "  -> Downstream 3384: -0.001284\n",
      "  -> Downstream 2677: 0.000713\n",
      "  -> Downstream 431: 0.000687\n",
      "  -> Downstream 2775: 0.000509\n",
      "  -> Downstream 1815: -0.000438\n",
      "  -> Downstream 1575: -0.000384\n",
      "  -> Downstream 545: 0.000281\n",
      "  -> Downstream 2041: 0.000274\n",
      "  -> Downstream 1489: -0.000268\n",
      "  -> Downstream 488: 0.000263\n",
      "  -> Downstream 4083: 0.000248\n",
      "  -> Downstream 3642: 0.000233\n",
      "  -> Downstream 2662: 0.000221\n",
      "  -> Downstream 1591: 0.000211\n",
      "  -> Downstream 2486: -0.000191\n",
      "  -> Downstream 1233: 0.000137\n",
      "  -> Downstream 3319: 0.000100\n",
      "  -> Downstream 2693: 0.000095\n",
      "  -> Downstream 2576: 0.000092\n",
      "  -> Downstream 3102: -0.000082\n",
      "  -> Downstream 3381: 0.000077\n",
      "  -> Downstream 2209: 0.000065\n",
      "  -> Downstream 2524: 0.000059\n",
      "  -> Downstream 2675: -0.000055\n",
      "  -> Downstream 1244: 0.000047\n",
      "  -> Downstream 2862: 0.000040\n",
      "  -> Downstream 576: 0.000040\n",
      "  -> Downstream 2166: 0.000039\n",
      "  -> Downstream 4042: -0.000036\n",
      "  -> Downstream 3864: 0.000034\n",
      "  -> Downstream 3368: 0.000032\n",
      "  -> Downstream 3682: -0.000029\n",
      "  -> Downstream 1605: 0.000025\n",
      "  -> Downstream 312: 0.000024\n",
      "  -> Downstream 3092: -0.000018\n",
      "  -> Downstream 2380: 0.000012\n",
      "  -> Downstream 3997: 0.000011\n",
      "  -> Downstream 1586: 0.000010\n",
      "  -> Downstream 3716: -0.000009\n",
      "  -> Downstream 2594: 0.000006\n",
      "  -> Downstream 1835: 0.000004\n",
      "\n",
      "Upstream feature 443:\n",
      "  -> Downstream 431: 0.001033\n",
      "  -> Downstream 2677: 0.001020\n",
      "  -> Downstream 2693: 0.000968\n",
      "  -> Downstream 3921: 0.000884\n",
      "  -> Downstream 3384: 0.000811\n",
      "  -> Downstream 4083: 0.000507\n",
      "  -> Downstream 488: 0.000467\n",
      "  -> Downstream 1575: -0.000415\n",
      "  -> Downstream 1489: 0.000414\n",
      "  -> Downstream 2166: 0.000362\n",
      "  -> Downstream 3864: 0.000326\n",
      "  -> Downstream 3381: 0.000277\n",
      "  -> Downstream 2486: 0.000257\n",
      "  -> Downstream 1591: -0.000207\n",
      "  -> Downstream 545: -0.000205\n",
      "  -> Downstream 2380: 0.000196\n",
      "  -> Downstream 3716: 0.000170\n",
      "  -> Downstream 2041: -0.000164\n",
      "  -> Downstream 3642: 0.000149\n",
      "  -> Downstream 1835: 0.000149\n",
      "  -> Downstream 2594: 0.000143\n",
      "  -> Downstream 2675: 0.000142\n",
      "  -> Downstream 4042: 0.000135\n",
      "  -> Downstream 3092: 0.000115\n",
      "  -> Downstream 3319: 0.000092\n",
      "  -> Downstream 2662: 0.000091\n",
      "  -> Downstream 3997: 0.000088\n",
      "  -> Downstream 1605: 0.000080\n",
      "  -> Downstream 2775: 0.000076\n",
      "  -> Downstream 3102: 0.000075\n",
      "  -> Downstream 2862: -0.000072\n",
      "  -> Downstream 3682: 0.000064\n",
      "  -> Downstream 1586: -0.000040\n",
      "  -> Downstream 1815: -0.000039\n",
      "  -> Downstream 312: 0.000034\n",
      "  -> Downstream 2576: -0.000030\n",
      "  -> Downstream 3368: 0.000021\n",
      "  -> Downstream 2524: -0.000019\n",
      "  -> Downstream 1244: 0.000018\n",
      "  -> Downstream 2209: 0.000007\n",
      "  -> Downstream 1233: -0.000002\n",
      "\n",
      "Upstream feature 481:\n",
      "  -> Downstream 431: -0.001826\n",
      "  -> Downstream 2486: 0.001216\n",
      "  -> Downstream 2677: -0.000906\n",
      "  -> Downstream 545: -0.000864\n",
      "  -> Downstream 3384: 0.000818\n",
      "  -> Downstream 1575: 0.000695\n",
      "  -> Downstream 3921: 0.000596\n",
      "  -> Downstream 3381: -0.000469\n",
      "  -> Downstream 1233: 0.000444\n",
      "  -> Downstream 3319: -0.000414\n",
      "  -> Downstream 488: -0.000400\n",
      "  -> Downstream 2662: 0.000360\n",
      "  -> Downstream 4083: -0.000332\n",
      "  -> Downstream 2380: -0.000305\n",
      "  -> Downstream 1605: -0.000243\n",
      "  -> Downstream 2209: -0.000226\n",
      "  -> Downstream 2041: -0.000201\n",
      "  -> Downstream 3716: -0.000161\n",
      "  -> Downstream 2862: -0.000152\n",
      "  -> Downstream 2693: -0.000143\n",
      "  -> Downstream 3092: 0.000141\n",
      "  -> Downstream 4042: 0.000122\n",
      "  -> Downstream 2166: 0.000120\n",
      "  -> Downstream 576: 0.000114\n",
      "  -> Downstream 312: 0.000111\n",
      "  -> Downstream 3642: -0.000108\n",
      "  -> Downstream 1244: -0.000108\n",
      "  -> Downstream 3102: -0.000094\n",
      "  -> Downstream 1815: -0.000091\n",
      "  -> Downstream 3997: -0.000088\n",
      "  -> Downstream 3368: -0.000085\n",
      "  -> Downstream 2576: -0.000059\n",
      "  -> Downstream 2775: -0.000059\n",
      "  -> Downstream 2675: -0.000056\n",
      "  -> Downstream 1591: 0.000052\n",
      "  -> Downstream 2594: -0.000048\n",
      "  -> Downstream 1586: 0.000035\n",
      "  -> Downstream 3864: 0.000023\n",
      "  -> Downstream 2524: -0.000016\n",
      "  -> Downstream 1835: -0.000009\n",
      "  -> Downstream 1489: 0.000007\n",
      "  -> Downstream 3682: -0.000004\n",
      "\n",
      "Upstream feature 495:\n",
      "  -> Downstream 3384: -0.002470\n",
      "  -> Downstream 1575: 0.001423\n",
      "  -> Downstream 545: -0.001237\n",
      "  -> Downstream 2775: 0.001190\n",
      "  -> Downstream 431: 0.000947\n",
      "  -> Downstream 1815: -0.000897\n",
      "  -> Downstream 1835: -0.000702\n",
      "  -> Downstream 488: 0.000676\n",
      "  -> Downstream 3921: -0.000641\n",
      "  -> Downstream 2677: 0.000614\n",
      "  -> Downstream 1591: -0.000603\n",
      "  -> Downstream 3642: 0.000574\n",
      "  -> Downstream 2486: -0.000534\n",
      "  -> Downstream 1233: 0.000499\n",
      "  -> Downstream 2380: 0.000476\n",
      "  -> Downstream 2693: 0.000436\n",
      "  -> Downstream 3381: 0.000410\n",
      "  -> Downstream 3092: 0.000402\n",
      "  -> Downstream 1489: 0.000390\n",
      "  -> Downstream 2166: 0.000349\n",
      "  -> Downstream 2662: -0.000234\n",
      "  -> Downstream 3102: -0.000226\n",
      "  -> Downstream 2209: -0.000204\n",
      "  -> Downstream 2576: 0.000201\n",
      "  -> Downstream 3864: -0.000197\n",
      "  -> Downstream 3997: 0.000136\n",
      "  -> Downstream 2862: 0.000134\n",
      "  -> Downstream 3716: -0.000130\n",
      "  -> Downstream 2675: -0.000128\n",
      "  -> Downstream 3682: -0.000124\n",
      "  -> Downstream 4083: 0.000110\n",
      "  -> Downstream 3368: -0.000109\n",
      "  -> Downstream 3319: -0.000104\n",
      "  -> Downstream 4042: 0.000102\n",
      "  -> Downstream 312: 0.000096\n",
      "  -> Downstream 2594: 0.000079\n",
      "  -> Downstream 1244: 0.000069\n",
      "  -> Downstream 576: -0.000057\n",
      "  -> Downstream 1605: -0.000051\n",
      "  -> Downstream 2524: -0.000048\n",
      "  -> Downstream 1586: -0.000002\n",
      "  -> Downstream 2041: -0.000001\n",
      "\n",
      "Upstream feature 794:\n",
      "  -> Downstream 2677: 0.002987\n",
      "  -> Downstream 4083: 0.001177\n",
      "  -> Downstream 2380: 0.000927\n",
      "  -> Downstream 1835: -0.000714\n",
      "  -> Downstream 1815: -0.000712\n",
      "  -> Downstream 3921: -0.000628\n",
      "  -> Downstream 3642: 0.000613\n",
      "  -> Downstream 3716: -0.000588\n",
      "  -> Downstream 1244: 0.000585\n",
      "  -> Downstream 2486: 0.000584\n",
      "  -> Downstream 488: -0.000507\n",
      "  -> Downstream 2662: 0.000505\n",
      "  -> Downstream 1489: -0.000433\n",
      "  -> Downstream 2166: -0.000402\n",
      "  -> Downstream 1575: 0.000301\n",
      "  -> Downstream 3092: 0.000299\n",
      "  -> Downstream 431: -0.000287\n",
      "  -> Downstream 2209: -0.000282\n",
      "  -> Downstream 3864: -0.000277\n",
      "  -> Downstream 2693: -0.000235\n",
      "  -> Downstream 312: 0.000203\n",
      "  -> Downstream 1591: -0.000198\n",
      "  -> Downstream 2524: -0.000152\n",
      "  -> Downstream 3384: -0.000141\n",
      "  -> Downstream 3319: -0.000134\n",
      "  -> Downstream 3102: -0.000126\n",
      "  -> Downstream 1605: -0.000116\n",
      "  -> Downstream 2775: 0.000110\n",
      "  -> Downstream 4042: 0.000103\n",
      "  -> Downstream 2576: -0.000078\n",
      "  -> Downstream 1233: 0.000066\n",
      "  -> Downstream 1586: 0.000059\n",
      "  -> Downstream 3381: -0.000057\n",
      "  -> Downstream 3682: -0.000047\n",
      "  -> Downstream 2041: -0.000047\n",
      "  -> Downstream 3997: 0.000040\n",
      "  -> Downstream 3368: -0.000034\n",
      "  -> Downstream 2594: -0.000034\n",
      "  -> Downstream 2675: 0.000021\n",
      "  -> Downstream 2862: 0.000020\n",
      "  -> Downstream 545: -0.000019\n",
      "  -> Downstream 576: 0.000002\n",
      "\n",
      "Upstream feature 798:\n",
      "  -> Downstream 431: 0.000496\n",
      "  -> Downstream 3384: -0.000467\n",
      "  -> Downstream 545: 0.000342\n",
      "  -> Downstream 2486: -0.000234\n",
      "  -> Downstream 1575: -0.000229\n",
      "  -> Downstream 2677: 0.000204\n",
      "  -> Downstream 1489: -0.000160\n",
      "  -> Downstream 488: 0.000153\n",
      "  -> Downstream 3642: -0.000134\n",
      "  -> Downstream 3092: -0.000129\n",
      "  -> Downstream 2041: 0.000090\n",
      "  -> Downstream 3319: 0.000086\n",
      "  -> Downstream 4083: 0.000076\n",
      "  -> Downstream 1605: 0.000071\n",
      "  -> Downstream 2775: -0.000071\n",
      "  -> Downstream 2693: 0.000070\n",
      "  -> Downstream 2209: 0.000064\n",
      "  -> Downstream 3716: 0.000056\n",
      "  -> Downstream 2166: -0.000046\n",
      "  -> Downstream 2662: 0.000046\n",
      "  -> Downstream 1815: 0.000041\n",
      "  -> Downstream 3368: 0.000039\n",
      "  -> Downstream 4042: -0.000035\n",
      "  -> Downstream 1835: 0.000032\n",
      "  -> Downstream 2862: 0.000026\n",
      "  -> Downstream 1586: -0.000026\n",
      "  -> Downstream 2524: 0.000023\n",
      "  -> Downstream 3864: 0.000014\n",
      "  -> Downstream 3997: 0.000014\n",
      "  -> Downstream 1233: -0.000013\n",
      "  -> Downstream 3921: -0.000012\n",
      "  -> Downstream 2576: -0.000011\n",
      "  -> Downstream 2380: 0.000008\n",
      "  -> Downstream 3102: 0.000008\n",
      "  -> Downstream 1244: 0.000008\n",
      "  -> Downstream 576: 0.000007\n",
      "  -> Downstream 2594: 0.000007\n",
      "  -> Downstream 312: -0.000004\n",
      "  -> Downstream 1591: 0.000002\n",
      "\n",
      "Upstream feature 816:\n",
      "  -> Downstream 2677: 0.004141\n",
      "  -> Downstream 3384: -0.002832\n",
      "  -> Downstream 2775: 0.002562\n",
      "  -> Downstream 431: 0.002163\n",
      "  -> Downstream 488: 0.001494\n",
      "  -> Downstream 1489: -0.001013\n",
      "  -> Downstream 3921: 0.000935\n",
      "  -> Downstream 2486: -0.000918\n",
      "  -> Downstream 545: 0.000720\n",
      "  -> Downstream 1815: -0.000610\n",
      "  -> Downstream 3381: 0.000602\n",
      "  -> Downstream 3642: 0.000596\n",
      "  -> Downstream 2380: 0.000584\n",
      "  -> Downstream 1835: 0.000555\n",
      "  -> Downstream 2662: -0.000555\n",
      "  -> Downstream 1244: 0.000521\n",
      "  -> Downstream 4083: 0.000501\n",
      "  -> Downstream 1233: -0.000485\n",
      "  -> Downstream 3092: -0.000467\n",
      "  -> Downstream 1591: -0.000343\n",
      "  -> Downstream 3682: 0.000337\n",
      "  -> Downstream 2041: 0.000335\n",
      "  -> Downstream 3319: 0.000325\n",
      "  -> Downstream 2693: 0.000298\n",
      "  -> Downstream 3102: 0.000236\n",
      "  -> Downstream 2576: 0.000210\n",
      "  -> Downstream 2209: 0.000181\n",
      "  -> Downstream 3716: -0.000157\n",
      "  -> Downstream 3368: 0.000154\n",
      "  -> Downstream 576: 0.000140\n",
      "  -> Downstream 2524: 0.000136\n",
      "  -> Downstream 2862: 0.000128\n",
      "  -> Downstream 1605: 0.000118\n",
      "  -> Downstream 3997: 0.000097\n",
      "  -> Downstream 2675: 0.000075\n",
      "  -> Downstream 4042: -0.000072\n",
      "  -> Downstream 3864: 0.000066\n",
      "  -> Downstream 2594: 0.000045\n",
      "  -> Downstream 312: 0.000041\n",
      "  -> Downstream 2166: -0.000037\n",
      "  -> Downstream 1575: 0.000016\n",
      "  -> Downstream 1586: 0.000004\n",
      "\n",
      "Upstream feature 897:\n",
      "  -> Downstream 2486: -0.000645\n",
      "  -> Downstream 3384: 0.000542\n",
      "  -> Downstream 431: 0.000439\n",
      "  -> Downstream 3642: -0.000408\n",
      "  -> Downstream 3381: 0.000387\n",
      "  -> Downstream 545: 0.000365\n",
      "  -> Downstream 2775: -0.000357\n",
      "  -> Downstream 2662: 0.000320\n",
      "  -> Downstream 3319: 0.000201\n",
      "  -> Downstream 2675: 0.000145\n",
      "  -> Downstream 2693: 0.000141\n",
      "  -> Downstream 2380: -0.000121\n",
      "  -> Downstream 3092: 0.000117\n",
      "  -> Downstream 1233: -0.000115\n",
      "  -> Downstream 3102: -0.000107\n",
      "  -> Downstream 1575: 0.000107\n",
      "  -> Downstream 3716: 0.000093\n",
      "  -> Downstream 3682: 0.000084\n",
      "  -> Downstream 3368: 0.000083\n",
      "  -> Downstream 312: 0.000079\n",
      "  -> Downstream 2166: 0.000071\n",
      "  -> Downstream 1591: 0.000069\n",
      "  -> Downstream 488: 0.000055\n",
      "  -> Downstream 3864: -0.000048\n",
      "  -> Downstream 2041: -0.000045\n",
      "  -> Downstream 1605: 0.000044\n",
      "  -> Downstream 1586: 0.000038\n",
      "  -> Downstream 2576: 0.000035\n",
      "  -> Downstream 1815: 0.000035\n",
      "  -> Downstream 1489: -0.000034\n",
      "  -> Downstream 4042: 0.000033\n",
      "  -> Downstream 3997: -0.000033\n",
      "  -> Downstream 2594: 0.000032\n",
      "  -> Downstream 2677: -0.000027\n",
      "  -> Downstream 4083: 0.000019\n",
      "  -> Downstream 576: 0.000018\n",
      "  -> Downstream 1835: -0.000017\n",
      "  -> Downstream 1244: -0.000017\n",
      "  -> Downstream 2524: -0.000013\n",
      "  -> Downstream 3921: 0.000008\n",
      "  -> Downstream 2862: 0.000002\n",
      "\n",
      "Upstream feature 963:\n",
      "  -> Downstream 3384: 0.002961\n",
      "  -> Downstream 2677: -0.002415\n",
      "  -> Downstream 2486: 0.000895\n",
      "  -> Downstream 545: -0.000841\n",
      "  -> Downstream 1815: 0.000829\n",
      "  -> Downstream 431: -0.000813\n",
      "  -> Downstream 3092: 0.000544\n",
      "  -> Downstream 3642: -0.000506\n",
      "  -> Downstream 488: -0.000447\n",
      "  -> Downstream 2380: -0.000429\n",
      "  -> Downstream 1575: 0.000405\n",
      "  -> Downstream 3921: -0.000404\n",
      "  -> Downstream 3716: 0.000392\n",
      "  -> Downstream 2166: 0.000347\n",
      "  -> Downstream 3381: -0.000327\n",
      "  -> Downstream 1244: -0.000287\n",
      "  -> Downstream 2041: -0.000266\n",
      "  -> Downstream 2209: -0.000263\n",
      "  -> Downstream 4083: -0.000253\n",
      "  -> Downstream 1835: -0.000231\n",
      "  -> Downstream 3319: -0.000222\n",
      "  -> Downstream 3864: -0.000169\n",
      "  -> Downstream 3102: -0.000152\n",
      "  -> Downstream 4042: 0.000132\n",
      "  -> Downstream 1605: -0.000120\n",
      "  -> Downstream 1233: -0.000120\n",
      "  -> Downstream 576: 0.000119\n",
      "  -> Downstream 312: 0.000112\n",
      "  -> Downstream 3368: -0.000087\n",
      "  -> Downstream 2576: -0.000067\n",
      "  -> Downstream 1586: 0.000065\n",
      "  -> Downstream 2524: -0.000054\n",
      "  -> Downstream 1489: 0.000045\n",
      "  -> Downstream 2662: -0.000045\n",
      "  -> Downstream 1591: 0.000040\n",
      "  -> Downstream 2862: -0.000032\n",
      "  -> Downstream 2775: -0.000023\n",
      "  -> Downstream 2675: -0.000021\n",
      "  -> Downstream 2594: -0.000006\n",
      "  -> Downstream 2693: 0.000005\n",
      "  -> Downstream 3997: 0.000004\n",
      "  -> Downstream 3682: 0.000001\n",
      "\n",
      "Upstream feature 992:\n",
      "  -> Downstream 3384: -0.003041\n",
      "  -> Downstream 545: -0.002063\n",
      "  -> Downstream 4083: 0.001410\n",
      "  -> Downstream 1489: -0.001306\n",
      "  -> Downstream 431: 0.000737\n",
      "  -> Downstream 1591: 0.000493\n",
      "  -> Downstream 2486: -0.000294\n",
      "  -> Downstream 3716: 0.000291\n",
      "  -> Downstream 1815: -0.000276\n",
      "  -> Downstream 2677: 0.000269\n",
      "  -> Downstream 3092: -0.000242\n",
      "  -> Downstream 2380: 0.000189\n",
      "  -> Downstream 2775: 0.000188\n",
      "  -> Downstream 488: 0.000147\n",
      "  -> Downstream 2524: 0.000136\n",
      "  -> Downstream 3381: 0.000131\n",
      "  -> Downstream 2209: 0.000123\n",
      "  -> Downstream 1575: -0.000123\n",
      "  -> Downstream 2662: 0.000120\n",
      "  -> Downstream 3102: -0.000106\n",
      "  -> Downstream 3921: 0.000088\n",
      "  -> Downstream 2693: 0.000086\n",
      "  -> Downstream 2166: 0.000085\n",
      "  -> Downstream 2862: 0.000076\n",
      "  -> Downstream 576: -0.000063\n",
      "  -> Downstream 1233: -0.000062\n",
      "  -> Downstream 1586: 0.000054\n",
      "  -> Downstream 1244: -0.000051\n",
      "  -> Downstream 3997: 0.000047\n",
      "  -> Downstream 2576: -0.000047\n",
      "  -> Downstream 3642: 0.000045\n",
      "  -> Downstream 3682: -0.000040\n",
      "  -> Downstream 2041: 0.000040\n",
      "  -> Downstream 1835: 0.000036\n",
      "  -> Downstream 3319: -0.000035\n",
      "  -> Downstream 1605: 0.000029\n",
      "  -> Downstream 312: -0.000028\n",
      "  -> Downstream 2675: -0.000027\n",
      "  -> Downstream 2594: 0.000015\n",
      "  -> Downstream 3864: 0.000005\n",
      "  -> Downstream 3368: -0.000003\n",
      "  -> Downstream 4042: 0.000001\n",
      "\n",
      "Upstream feature 1096:\n",
      "  -> Downstream 2677: 0.004799\n",
      "  -> Downstream 3384: -0.001628\n",
      "  -> Downstream 2775: 0.001446\n",
      "  -> Downstream 545: 0.000990\n",
      "  -> Downstream 488: 0.000721\n",
      "  -> Downstream 431: 0.000624\n",
      "  -> Downstream 2380: 0.000611\n",
      "  -> Downstream 3642: 0.000510\n",
      "  -> Downstream 2486: -0.000430\n",
      "  -> Downstream 1575: -0.000405\n",
      "  -> Downstream 1489: -0.000386\n",
      "  -> Downstream 1233: -0.000309\n",
      "  -> Downstream 1591: 0.000256\n",
      "  -> Downstream 3682: 0.000247\n",
      "  -> Downstream 1835: 0.000229\n",
      "  -> Downstream 4083: 0.000197\n",
      "  -> Downstream 576: 0.000156\n",
      "  -> Downstream 3716: 0.000156\n",
      "  -> Downstream 2662: -0.000153\n",
      "  -> Downstream 2209: 0.000143\n",
      "  -> Downstream 312: 0.000139\n",
      "  -> Downstream 2041: 0.000139\n",
      "  -> Downstream 3319: 0.000115\n",
      "  -> Downstream 2693: 0.000114\n",
      "  -> Downstream 4042: 0.000108\n",
      "  -> Downstream 3102: -0.000101\n",
      "  -> Downstream 2862: 0.000100\n",
      "  -> Downstream 1815: 0.000099\n",
      "  -> Downstream 3368: 0.000098\n",
      "  -> Downstream 2166: 0.000092\n",
      "  -> Downstream 3921: -0.000082\n",
      "  -> Downstream 1244: -0.000082\n",
      "  -> Downstream 2594: 0.000056\n",
      "  -> Downstream 2576: 0.000049\n",
      "  -> Downstream 2524: -0.000048\n",
      "  -> Downstream 2675: 0.000038\n",
      "  -> Downstream 3381: -0.000028\n",
      "  -> Downstream 3864: 0.000024\n",
      "  -> Downstream 3092: -0.000024\n",
      "  -> Downstream 3997: -0.000003\n",
      "  -> Downstream 1586: -0.000003\n",
      "\n",
      "Upstream feature 1297:\n",
      "  -> Downstream 3384: -0.016360\n",
      "  -> Downstream 2677: 0.008073\n",
      "  -> Downstream 1815: -0.004237\n",
      "  -> Downstream 2380: 0.003090\n",
      "  -> Downstream 2775: 0.002273\n",
      "  -> Downstream 2486: -0.001958\n",
      "  -> Downstream 488: 0.001932\n",
      "  -> Downstream 431: 0.001640\n",
      "  -> Downstream 545: 0.001560\n",
      "  -> Downstream 1835: 0.001507\n",
      "  -> Downstream 1591: -0.001319\n",
      "  -> Downstream 1244: 0.001166\n",
      "  -> Downstream 4083: 0.001073\n",
      "  -> Downstream 2041: 0.000945\n",
      "  -> Downstream 3682: 0.000944\n",
      "  -> Downstream 1575: 0.000849\n",
      "  -> Downstream 3864: -0.000697\n",
      "  -> Downstream 3092: -0.000636\n",
      "  -> Downstream 3642: 0.000590\n",
      "  -> Downstream 3921: 0.000590\n",
      "  -> Downstream 2209: 0.000525\n",
      "  -> Downstream 2662: -0.000525\n",
      "  -> Downstream 3381: -0.000505\n",
      "  -> Downstream 1233: 0.000399\n",
      "  -> Downstream 2576: 0.000391\n",
      "  -> Downstream 312: -0.000326\n",
      "  -> Downstream 1605: 0.000268\n",
      "  -> Downstream 2166: 0.000257\n",
      "  -> Downstream 2675: -0.000221\n",
      "  -> Downstream 3716: -0.000180\n",
      "  -> Downstream 4042: 0.000179\n",
      "  -> Downstream 2594: -0.000162\n",
      "  -> Downstream 576: -0.000146\n",
      "  -> Downstream 1489: 0.000140\n",
      "  -> Downstream 1586: 0.000123\n",
      "  -> Downstream 3997: 0.000111\n",
      "  -> Downstream 3319: 0.000087\n",
      "  -> Downstream 3102: -0.000059\n",
      "  -> Downstream 3368: 0.000059\n",
      "  -> Downstream 2693: -0.000053\n",
      "  -> Downstream 2862: -0.000031\n",
      "  -> Downstream 2524: -0.000010\n",
      "\n",
      "Upstream feature 1370:\n",
      "  -> Downstream 4083: -0.001283\n",
      "  -> Downstream 2775: -0.001090\n",
      "  -> Downstream 3384: 0.001011\n",
      "  -> Downstream 431: -0.000854\n",
      "  -> Downstream 1233: 0.000580\n",
      "  -> Downstream 1835: -0.000535\n",
      "  -> Downstream 2486: 0.000442\n",
      "  -> Downstream 1815: -0.000438\n",
      "  -> Downstream 3716: -0.000186\n",
      "  -> Downstream 2662: 0.000177\n",
      "  -> Downstream 3368: 0.000165\n",
      "  -> Downstream 1575: -0.000147\n",
      "  -> Downstream 3381: 0.000139\n",
      "  -> Downstream 2524: 0.000138\n",
      "  -> Downstream 3682: 0.000134\n",
      "  -> Downstream 2166: 0.000115\n",
      "  -> Downstream 2675: -0.000099\n",
      "  -> Downstream 3864: 0.000092\n",
      "  -> Downstream 3642: -0.000092\n",
      "  -> Downstream 2380: -0.000088\n",
      "  -> Downstream 1244: 0.000085\n",
      "  -> Downstream 3092: 0.000080\n",
      "  -> Downstream 1591: -0.000079\n",
      "  -> Downstream 545: 0.000073\n",
      "  -> Downstream 2677: -0.000071\n",
      "  -> Downstream 2209: 0.000065\n",
      "  -> Downstream 1489: 0.000044\n",
      "  -> Downstream 576: -0.000037\n",
      "  -> Downstream 3319: 0.000037\n",
      "  -> Downstream 3102: 0.000035\n",
      "  -> Downstream 3997: 0.000034\n",
      "  -> Downstream 312: 0.000030\n",
      "  -> Downstream 1586: 0.000025\n",
      "  -> Downstream 3921: -0.000024\n",
      "  -> Downstream 488: -0.000022\n",
      "  -> Downstream 2693: 0.000020\n",
      "  -> Downstream 2594: 0.000014\n",
      "  -> Downstream 2862: 0.000010\n",
      "  -> Downstream 1605: 0.000009\n",
      "  -> Downstream 4042: 0.000005\n",
      "  -> Downstream 2576: -0.000002\n",
      "  -> Downstream 2041: 0.000002\n",
      "\n",
      "Upstream feature 1474:\n",
      "  -> Downstream 3384: 0.004032\n",
      "  -> Downstream 3921: -0.003419\n",
      "  -> Downstream 2775: -0.003295\n",
      "  -> Downstream 1591: 0.001429\n",
      "  -> Downstream 1489: 0.001337\n",
      "  -> Downstream 3642: -0.001267\n",
      "  -> Downstream 1575: 0.001257\n",
      "  -> Downstream 488: -0.001046\n",
      "  -> Downstream 1233: -0.000883\n",
      "  -> Downstream 2380: -0.000735\n",
      "  -> Downstream 2677: -0.000610\n",
      "  -> Downstream 576: -0.000478\n",
      "  -> Downstream 1815: 0.000445\n",
      "  -> Downstream 3381: -0.000435\n",
      "  -> Downstream 2166: 0.000418\n",
      "  -> Downstream 3319: -0.000392\n",
      "  -> Downstream 2693: -0.000390\n",
      "  -> Downstream 3864: -0.000370\n",
      "  -> Downstream 4083: -0.000308\n",
      "  -> Downstream 312: -0.000287\n",
      "  -> Downstream 2524: -0.000283\n",
      "  -> Downstream 3682: 0.000270\n",
      "  -> Downstream 2662: -0.000265\n",
      "  -> Downstream 2209: -0.000263\n",
      "  -> Downstream 431: -0.000249\n",
      "  -> Downstream 2486: 0.000238\n",
      "  -> Downstream 1835: -0.000209\n",
      "  -> Downstream 2041: -0.000195\n",
      "  -> Downstream 1605: -0.000178\n",
      "  -> Downstream 1244: -0.000173\n",
      "  -> Downstream 2594: -0.000142\n",
      "  -> Downstream 2862: -0.000107\n",
      "  -> Downstream 3716: -0.000106\n",
      "  -> Downstream 2576: -0.000102\n",
      "  -> Downstream 545: 0.000087\n",
      "  -> Downstream 3997: -0.000080\n",
      "  -> Downstream 3368: -0.000065\n",
      "  -> Downstream 1586: 0.000058\n",
      "  -> Downstream 4042: -0.000058\n",
      "  -> Downstream 2675: 0.000053\n",
      "  -> Downstream 3102: -0.000042\n",
      "  -> Downstream 3092: 0.000005\n",
      "\n",
      "Upstream feature 1682:\n",
      "  -> Downstream 3384: 0.005861\n",
      "  -> Downstream 2677: -0.003406\n",
      "  -> Downstream 431: -0.001492\n",
      "  -> Downstream 2380: -0.001157\n",
      "  -> Downstream 1489: 0.001006\n",
      "  -> Downstream 3921: 0.000950\n",
      "  -> Downstream 1244: -0.000895\n",
      "  -> Downstream 2486: 0.000895\n",
      "  -> Downstream 1835: -0.000654\n",
      "  -> Downstream 3642: -0.000589\n",
      "  -> Downstream 1233: 0.000535\n",
      "  -> Downstream 545: -0.000512\n",
      "  -> Downstream 488: -0.000306\n",
      "  -> Downstream 3092: 0.000274\n",
      "  -> Downstream 1815: 0.000271\n",
      "  -> Downstream 3381: -0.000239\n",
      "  -> Downstream 4083: -0.000235\n",
      "  -> Downstream 2775: 0.000234\n",
      "  -> Downstream 1575: 0.000212\n",
      "  -> Downstream 3864: -0.000200\n",
      "  -> Downstream 2693: -0.000183\n",
      "  -> Downstream 576: -0.000179\n",
      "  -> Downstream 2209: -0.000140\n",
      "  -> Downstream 2675: -0.000133\n",
      "  -> Downstream 312: -0.000130\n",
      "  -> Downstream 3368: -0.000126\n",
      "  -> Downstream 2576: 0.000094\n",
      "  -> Downstream 2166: 0.000088\n",
      "  -> Downstream 1605: -0.000075\n",
      "  -> Downstream 3319: -0.000072\n",
      "  -> Downstream 2862: -0.000072\n",
      "  -> Downstream 3682: 0.000067\n",
      "  -> Downstream 1591: -0.000056\n",
      "  -> Downstream 2594: 0.000030\n",
      "  -> Downstream 3716: 0.000030\n",
      "  -> Downstream 1586: 0.000029\n",
      "  -> Downstream 3102: 0.000025\n",
      "  -> Downstream 2524: -0.000015\n",
      "  -> Downstream 4042: 0.000014\n",
      "  -> Downstream 2662: -0.000013\n",
      "  -> Downstream 2041: -0.000009\n",
      "  -> Downstream 3997: 0.000004\n",
      "\n",
      "Upstream feature 1690:\n",
      "  -> Downstream 1489: -0.003275\n",
      "  -> Downstream 3384: -0.002337\n",
      "  -> Downstream 545: -0.001697\n",
      "  -> Downstream 431: -0.001298\n",
      "  -> Downstream 488: -0.001093\n",
      "  -> Downstream 1575: 0.000836\n",
      "  -> Downstream 3092: 0.000780\n",
      "  -> Downstream 2166: 0.000766\n",
      "  -> Downstream 2775: 0.000749\n",
      "  -> Downstream 3381: -0.000695\n",
      "  -> Downstream 2486: 0.000687\n",
      "  -> Downstream 3642: 0.000672\n",
      "  -> Downstream 3921: -0.000512\n",
      "  -> Downstream 2380: 0.000483\n",
      "  -> Downstream 1233: -0.000429\n",
      "  -> Downstream 2041: -0.000422\n",
      "  -> Downstream 1605: -0.000395\n",
      "  -> Downstream 1591: 0.000370\n",
      "  -> Downstream 3319: -0.000354\n",
      "  -> Downstream 2209: -0.000329\n",
      "  -> Downstream 1835: 0.000300\n",
      "  -> Downstream 4042: 0.000285\n",
      "  -> Downstream 576: 0.000227\n",
      "  -> Downstream 2524: -0.000214\n",
      "  -> Downstream 2662: 0.000184\n",
      "  -> Downstream 2693: -0.000175\n",
      "  -> Downstream 3102: -0.000169\n",
      "  -> Downstream 2677: 0.000162\n",
      "  -> Downstream 1586: 0.000156\n",
      "  -> Downstream 4083: 0.000114\n",
      "  -> Downstream 1815: -0.000098\n",
      "  -> Downstream 2675: -0.000095\n",
      "  -> Downstream 3716: -0.000095\n",
      "  -> Downstream 312: 0.000092\n",
      "  -> Downstream 2862: -0.000072\n",
      "  -> Downstream 3997: -0.000063\n",
      "  -> Downstream 2576: -0.000063\n",
      "  -> Downstream 3368: -0.000053\n",
      "  -> Downstream 1244: 0.000045\n",
      "  -> Downstream 2594: -0.000023\n",
      "  -> Downstream 3864: 0.000021\n",
      "  -> Downstream 3682: 0.000005\n",
      "\n",
      "Upstream feature 1712:\n",
      "  -> Downstream 3921: -0.001762\n",
      "  -> Downstream 431: -0.001283\n",
      "  -> Downstream 545: 0.001192\n",
      "  -> Downstream 4083: 0.000978\n",
      "  -> Downstream 1575: 0.000974\n",
      "  -> Downstream 488: -0.000702\n",
      "  -> Downstream 2486: 0.000663\n",
      "  -> Downstream 1489: -0.000636\n",
      "  -> Downstream 2677: -0.000545\n",
      "  -> Downstream 3381: -0.000528\n",
      "  -> Downstream 3384: 0.000512\n",
      "  -> Downstream 3092: 0.000482\n",
      "  -> Downstream 2662: 0.000470\n",
      "  -> Downstream 3642: 0.000414\n",
      "  -> Downstream 3319: -0.000403\n",
      "  -> Downstream 2693: -0.000324\n",
      "  -> Downstream 2524: -0.000222\n",
      "  -> Downstream 2209: -0.000218\n",
      "  -> Downstream 1586: 0.000199\n",
      "  -> Downstream 1605: -0.000198\n",
      "  -> Downstream 3102: -0.000187\n",
      "  -> Downstream 3716: -0.000149\n",
      "  -> Downstream 3368: -0.000148\n",
      "  -> Downstream 1815: -0.000138\n",
      "  -> Downstream 2166: 0.000109\n",
      "  -> Downstream 3864: -0.000106\n",
      "  -> Downstream 1233: 0.000084\n",
      "  -> Downstream 2862: -0.000074\n",
      "  -> Downstream 3997: -0.000073\n",
      "  -> Downstream 4042: 0.000073\n",
      "  -> Downstream 2775: 0.000066\n",
      "  -> Downstream 1244: -0.000054\n",
      "  -> Downstream 2041: -0.000051\n",
      "  -> Downstream 2675: -0.000048\n",
      "  -> Downstream 312: -0.000048\n",
      "  -> Downstream 2380: -0.000047\n",
      "  -> Downstream 1835: -0.000044\n",
      "  -> Downstream 1591: 0.000044\n",
      "  -> Downstream 3682: 0.000040\n",
      "  -> Downstream 2576: 0.000010\n",
      "  -> Downstream 2594: -0.000003\n",
      "\n",
      "Upstream feature 1807:\n",
      "  -> Downstream 3642: -0.002388\n",
      "  -> Downstream 2775: -0.002210\n",
      "  -> Downstream 3384: 0.001725\n",
      "  -> Downstream 431: -0.001174\n",
      "  -> Downstream 1575: 0.000713\n",
      "  -> Downstream 2677: -0.000707\n",
      "  -> Downstream 488: -0.000639\n",
      "  -> Downstream 1835: -0.000589\n",
      "  -> Downstream 545: 0.000458\n",
      "  -> Downstream 1233: 0.000449\n",
      "  -> Downstream 2486: 0.000351\n",
      "  -> Downstream 3921: 0.000350\n",
      "  -> Downstream 2380: -0.000286\n",
      "  -> Downstream 1489: 0.000286\n",
      "  -> Downstream 1591: 0.000264\n",
      "  -> Downstream 3092: 0.000214\n",
      "  -> Downstream 2209: -0.000211\n",
      "  -> Downstream 3381: 0.000136\n",
      "  -> Downstream 2693: -0.000129\n",
      "  -> Downstream 4083: -0.000125\n",
      "  -> Downstream 576: -0.000117\n",
      "  -> Downstream 1244: -0.000113\n",
      "  -> Downstream 2041: -0.000109\n",
      "  -> Downstream 1605: -0.000098\n",
      "  -> Downstream 2675: 0.000086\n",
      "  -> Downstream 3319: -0.000078\n",
      "  -> Downstream 3716: -0.000077\n",
      "  -> Downstream 2166: -0.000072\n",
      "  -> Downstream 2576: 0.000071\n",
      "  -> Downstream 312: 0.000066\n",
      "  -> Downstream 3864: 0.000065\n",
      "  -> Downstream 1586: 0.000064\n",
      "  -> Downstream 3368: -0.000057\n",
      "  -> Downstream 3682: -0.000056\n",
      "  -> Downstream 3997: 0.000054\n",
      "  -> Downstream 1815: -0.000050\n",
      "  -> Downstream 2862: -0.000033\n",
      "  -> Downstream 3102: 0.000022\n",
      "  -> Downstream 2524: -0.000014\n",
      "  -> Downstream 2594: -0.000012\n",
      "  -> Downstream 4042: 0.000009\n",
      "\n",
      "Upstream feature 1890:\n",
      "  -> Downstream 3921: 0.002891\n",
      "  -> Downstream 3384: -0.002866\n",
      "  -> Downstream 2677: 0.001418\n",
      "  -> Downstream 2775: -0.001150\n",
      "  -> Downstream 545: 0.000968\n",
      "  -> Downstream 1233: -0.000682\n",
      "  -> Downstream 1489: -0.000646\n",
      "  -> Downstream 2166: 0.000546\n",
      "  -> Downstream 1244: 0.000502\n",
      "  -> Downstream 1815: 0.000331\n",
      "  -> Downstream 431: -0.000280\n",
      "  -> Downstream 3716: -0.000270\n",
      "  -> Downstream 1835: 0.000234\n",
      "  -> Downstream 4083: 0.000214\n",
      "  -> Downstream 3092: -0.000212\n",
      "  -> Downstream 2675: 0.000194\n",
      "  -> Downstream 2576: -0.000180\n",
      "  -> Downstream 2486: 0.000177\n",
      "  -> Downstream 3682: -0.000171\n",
      "  -> Downstream 488: 0.000171\n",
      "  -> Downstream 3642: 0.000167\n",
      "  -> Downstream 1605: 0.000167\n",
      "  -> Downstream 576: -0.000164\n",
      "  -> Downstream 4042: 0.000161\n",
      "  -> Downstream 2662: -0.000156\n",
      "  -> Downstream 3102: 0.000151\n",
      "  -> Downstream 3864: -0.000143\n",
      "  -> Downstream 3381: -0.000141\n",
      "  -> Downstream 1575: -0.000139\n",
      "  -> Downstream 2380: 0.000124\n",
      "  -> Downstream 3997: -0.000123\n",
      "  -> Downstream 312: -0.000118\n",
      "  -> Downstream 1591: -0.000100\n",
      "  -> Downstream 2041: -0.000081\n",
      "  -> Downstream 3319: -0.000081\n",
      "  -> Downstream 2524: -0.000070\n",
      "  -> Downstream 1586: -0.000066\n",
      "  -> Downstream 2594: 0.000058\n",
      "  -> Downstream 3368: 0.000057\n",
      "  -> Downstream 2862: 0.000052\n",
      "  -> Downstream 2693: -0.000049\n",
      "  -> Downstream 2209: -0.000022\n",
      "\n",
      "Upstream feature 2277:\n",
      "  -> Downstream 2677: -0.006000\n",
      "  -> Downstream 3384: 0.004354\n",
      "  -> Downstream 2380: -0.001219\n",
      "  -> Downstream 3642: -0.001173\n",
      "  -> Downstream 2775: -0.001076\n",
      "  -> Downstream 1575: 0.000985\n",
      "  -> Downstream 3921: 0.000966\n",
      "  -> Downstream 488: -0.000941\n",
      "  -> Downstream 1489: 0.000843\n",
      "  -> Downstream 1815: 0.000837\n",
      "  -> Downstream 1244: -0.000748\n",
      "  -> Downstream 2486: 0.000745\n",
      "  -> Downstream 545: -0.000695\n",
      "  -> Downstream 431: -0.000619\n",
      "  -> Downstream 1835: -0.000380\n",
      "  -> Downstream 2166: 0.000308\n",
      "  -> Downstream 3319: -0.000299\n",
      "  -> Downstream 3682: 0.000282\n",
      "  -> Downstream 2209: -0.000271\n",
      "  -> Downstream 3092: 0.000265\n",
      "  -> Downstream 4083: -0.000252\n",
      "  -> Downstream 2662: 0.000247\n",
      "  -> Downstream 3864: -0.000241\n",
      "  -> Downstream 3716: 0.000229\n",
      "  -> Downstream 3368: -0.000168\n",
      "  -> Downstream 1591: -0.000142\n",
      "  -> Downstream 2862: -0.000137\n",
      "  -> Downstream 3381: -0.000113\n",
      "  -> Downstream 312: -0.000106\n",
      "  -> Downstream 2576: 0.000092\n",
      "  -> Downstream 1586: 0.000082\n",
      "  -> Downstream 4042: 0.000060\n",
      "  -> Downstream 2675: -0.000050\n",
      "  -> Downstream 1605: -0.000048\n",
      "  -> Downstream 2041: -0.000047\n",
      "  -> Downstream 2524: -0.000046\n",
      "  -> Downstream 2594: -0.000034\n",
      "  -> Downstream 3102: -0.000018\n",
      "  -> Downstream 1233: 0.000016\n",
      "  -> Downstream 576: -0.000009\n",
      "  -> Downstream 2693: -0.000007\n",
      "  -> Downstream 3997: 0.000005\n",
      "\n",
      "Upstream feature 2311:\n",
      "  -> Downstream 3921: -0.003485\n",
      "  -> Downstream 431: -0.002689\n",
      "  -> Downstream 2677: -0.001815\n",
      "  -> Downstream 545: -0.001606\n",
      "  -> Downstream 1575: 0.001537\n",
      "  -> Downstream 4083: -0.001506\n",
      "  -> Downstream 3384: -0.001064\n",
      "  -> Downstream 2486: 0.000859\n",
      "  -> Downstream 1835: 0.000759\n",
      "  -> Downstream 3092: 0.000737\n",
      "  -> Downstream 2662: 0.000649\n",
      "  -> Downstream 1489: 0.000638\n",
      "  -> Downstream 3102: -0.000528\n",
      "  -> Downstream 1815: -0.000431\n",
      "  -> Downstream 2209: -0.000395\n",
      "  -> Downstream 1586: 0.000373\n",
      "  -> Downstream 1591: -0.000372\n",
      "  -> Downstream 576: 0.000362\n",
      "  -> Downstream 1605: -0.000354\n",
      "  -> Downstream 488: 0.000349\n",
      "  -> Downstream 2380: 0.000348\n",
      "  -> Downstream 4042: 0.000319\n",
      "  -> Downstream 2041: -0.000288\n",
      "  -> Downstream 3716: -0.000278\n",
      "  -> Downstream 2166: -0.000265\n",
      "  -> Downstream 3864: 0.000249\n",
      "  -> Downstream 3642: 0.000226\n",
      "  -> Downstream 3381: -0.000223\n",
      "  -> Downstream 2675: -0.000178\n",
      "  -> Downstream 3997: 0.000162\n",
      "  -> Downstream 1244: 0.000149\n",
      "  -> Downstream 3368: -0.000147\n",
      "  -> Downstream 3319: -0.000131\n",
      "  -> Downstream 2775: 0.000124\n",
      "  -> Downstream 3682: 0.000111\n",
      "  -> Downstream 1233: 0.000099\n",
      "  -> Downstream 2862: -0.000091\n",
      "  -> Downstream 2693: -0.000091\n",
      "  -> Downstream 2524: -0.000046\n",
      "  -> Downstream 2576: 0.000025\n",
      "  -> Downstream 312: 0.000013\n",
      "  -> Downstream 2594: -0.000001\n",
      "\n",
      "Upstream feature 2340:\n",
      "  -> Downstream 2677: 0.005898\n",
      "  -> Downstream 3384: -0.002291\n",
      "  -> Downstream 1575: -0.001917\n",
      "  -> Downstream 1489: -0.001664\n",
      "  -> Downstream 431: 0.001610\n",
      "  -> Downstream 488: 0.001355\n",
      "  -> Downstream 2486: -0.001333\n",
      "  -> Downstream 2662: -0.001006\n",
      "  -> Downstream 4083: 0.001002\n",
      "  -> Downstream 1244: 0.001001\n",
      "  -> Downstream 545: 0.000799\n",
      "  -> Downstream 2166: 0.000776\n",
      "  -> Downstream 1835: 0.000710\n",
      "  -> Downstream 3642: 0.000703\n",
      "  -> Downstream 1233: -0.000699\n",
      "  -> Downstream 1815: -0.000689\n",
      "  -> Downstream 2380: 0.000682\n",
      "  -> Downstream 3092: -0.000647\n",
      "  -> Downstream 1605: 0.000631\n",
      "  -> Downstream 1591: -0.000607\n",
      "  -> Downstream 3319: 0.000605\n",
      "  -> Downstream 2209: 0.000511\n",
      "  -> Downstream 3921: -0.000464\n",
      "  -> Downstream 3864: 0.000426\n",
      "  -> Downstream 3381: 0.000404\n",
      "  -> Downstream 2693: 0.000402\n",
      "  -> Downstream 312: 0.000330\n",
      "  -> Downstream 3102: 0.000321\n",
      "  -> Downstream 2775: 0.000302\n",
      "  -> Downstream 2862: 0.000293\n",
      "  -> Downstream 576: 0.000288\n",
      "  -> Downstream 2524: 0.000273\n",
      "  -> Downstream 3368: 0.000252\n",
      "  -> Downstream 2594: 0.000166\n",
      "  -> Downstream 3716: -0.000148\n",
      "  -> Downstream 2675: 0.000146\n",
      "  -> Downstream 1586: -0.000086\n",
      "  -> Downstream 4042: -0.000079\n",
      "  -> Downstream 3997: 0.000053\n",
      "  -> Downstream 2576: -0.000050\n",
      "  -> Downstream 2041: -0.000049\n",
      "  -> Downstream 3682: 0.000031\n",
      "\n",
      "Upstream feature 2443:\n",
      "  -> Downstream 431: -0.001373\n",
      "  -> Downstream 2677: -0.001043\n",
      "  -> Downstream 488: -0.000791\n",
      "  -> Downstream 2486: 0.000716\n",
      "  -> Downstream 1575: 0.000671\n",
      "  -> Downstream 3921: -0.000601\n",
      "  -> Downstream 2662: 0.000482\n",
      "  -> Downstream 3092: 0.000464\n",
      "  -> Downstream 3642: 0.000377\n",
      "  -> Downstream 2693: -0.000364\n",
      "  -> Downstream 3384: 0.000359\n",
      "  -> Downstream 3319: -0.000354\n",
      "  -> Downstream 2775: 0.000278\n",
      "  -> Downstream 2041: -0.000242\n",
      "  -> Downstream 3864: -0.000225\n",
      "  -> Downstream 3102: -0.000218\n",
      "  -> Downstream 2209: -0.000213\n",
      "  -> Downstream 1835: -0.000210\n",
      "  -> Downstream 1489: -0.000210\n",
      "  -> Downstream 2524: -0.000191\n",
      "  -> Downstream 1605: -0.000177\n",
      "  -> Downstream 2166: 0.000170\n",
      "  -> Downstream 4083: 0.000145\n",
      "  -> Downstream 1591: 0.000139\n",
      "  -> Downstream 3368: -0.000138\n",
      "  -> Downstream 545: -0.000133\n",
      "  -> Downstream 4042: 0.000131\n",
      "  -> Downstream 2862: -0.000131\n",
      "  -> Downstream 3716: -0.000093\n",
      "  -> Downstream 3682: 0.000088\n",
      "  -> Downstream 1586: 0.000067\n",
      "  -> Downstream 2675: -0.000067\n",
      "  -> Downstream 1233: -0.000058\n",
      "  -> Downstream 3997: -0.000057\n",
      "  -> Downstream 312: -0.000051\n",
      "  -> Downstream 2594: -0.000045\n",
      "  -> Downstream 1244: -0.000034\n",
      "  -> Downstream 2380: -0.000033\n",
      "  -> Downstream 2576: 0.000032\n",
      "  -> Downstream 1815: 0.000025\n",
      "  -> Downstream 576: 0.000014\n",
      "\n",
      "Upstream feature 2672:\n",
      "  -> Downstream 3384: 0.007139\n",
      "  -> Downstream 2677: -0.006552\n",
      "  -> Downstream 3921: 0.002339\n",
      "  -> Downstream 1489: 0.002133\n",
      "  -> Downstream 2775: -0.002087\n",
      "  -> Downstream 2486: 0.001811\n",
      "  -> Downstream 488: -0.001607\n",
      "  -> Downstream 431: -0.001600\n",
      "  -> Downstream 1244: -0.001350\n",
      "  -> Downstream 2380: -0.001343\n",
      "  -> Downstream 1233: 0.001158\n",
      "  -> Downstream 1835: -0.001052\n",
      "  -> Downstream 2662: 0.000896\n",
      "  -> Downstream 1575: 0.000740\n",
      "  -> Downstream 4083: -0.000691\n",
      "  -> Downstream 3642: -0.000603\n",
      "  -> Downstream 545: -0.000455\n",
      "  -> Downstream 2693: -0.000414\n",
      "  -> Downstream 576: -0.000395\n",
      "  -> Downstream 1591: 0.000387\n",
      "  -> Downstream 2041: -0.000355\n",
      "  -> Downstream 3864: -0.000311\n",
      "  -> Downstream 2209: -0.000305\n",
      "  -> Downstream 1815: 0.000302\n",
      "  -> Downstream 3381: -0.000278\n",
      "  -> Downstream 3319: -0.000237\n",
      "  -> Downstream 3368: -0.000228\n",
      "  -> Downstream 3092: 0.000211\n",
      "  -> Downstream 2524: -0.000202\n",
      "  -> Downstream 3716: -0.000200\n",
      "  -> Downstream 1605: -0.000175\n",
      "  -> Downstream 2862: -0.000169\n",
      "  -> Downstream 2576: 0.000138\n",
      "  -> Downstream 312: -0.000131\n",
      "  -> Downstream 2594: -0.000125\n",
      "  -> Downstream 1586: -0.000113\n",
      "  -> Downstream 3682: 0.000105\n",
      "  -> Downstream 3997: -0.000062\n",
      "  -> Downstream 4042: -0.000046\n",
      "  -> Downstream 3102: 0.000039\n",
      "  -> Downstream 2166: -0.000032\n",
      "  -> Downstream 2675: -0.000032\n",
      "\n",
      "Upstream feature 2850:\n",
      "  -> Downstream 3384: 0.001865\n",
      "  -> Downstream 2775: -0.001661\n",
      "  -> Downstream 3921: -0.001479\n",
      "  -> Downstream 2677: 0.001020\n",
      "  -> Downstream 1489: 0.000880\n",
      "  -> Downstream 488: 0.000729\n",
      "  -> Downstream 2166: -0.000559\n",
      "  -> Downstream 431: 0.000530\n",
      "  -> Downstream 3092: -0.000493\n",
      "  -> Downstream 2662: -0.000484\n",
      "  -> Downstream 545: 0.000441\n",
      "  -> Downstream 1591: -0.000416\n",
      "  -> Downstream 1575: -0.000409\n",
      "  -> Downstream 2486: -0.000403\n",
      "  -> Downstream 4083: 0.000351\n",
      "  -> Downstream 3381: 0.000297\n",
      "  -> Downstream 576: -0.000209\n",
      "  -> Downstream 3319: 0.000205\n",
      "  -> Downstream 3864: 0.000159\n",
      "  -> Downstream 1605: 0.000125\n",
      "  -> Downstream 1815: -0.000122\n",
      "  -> Downstream 2675: 0.000112\n",
      "  -> Downstream 2693: 0.000109\n",
      "  -> Downstream 1244: 0.000103\n",
      "  -> Downstream 312: 0.000096\n",
      "  -> Downstream 3642: -0.000090\n",
      "  -> Downstream 2209: 0.000078\n",
      "  -> Downstream 4042: 0.000066\n",
      "  -> Downstream 3368: 0.000066\n",
      "  -> Downstream 2524: 0.000063\n",
      "  -> Downstream 3102: 0.000056\n",
      "  -> Downstream 2862: 0.000055\n",
      "  -> Downstream 3716: 0.000051\n",
      "  -> Downstream 1835: 0.000048\n",
      "  -> Downstream 2380: 0.000043\n",
      "  -> Downstream 2576: 0.000027\n",
      "  -> Downstream 2041: -0.000027\n",
      "  -> Downstream 1586: -0.000019\n",
      "  -> Downstream 3997: -0.000012\n",
      "  -> Downstream 3682: 0.000006\n",
      "  -> Downstream 1233: 0.000003\n",
      "  -> Downstream 2594: 0.000001\n",
      "\n",
      "Upstream feature 2956:\n",
      "  -> Downstream 3384: 0.007671\n",
      "  -> Downstream 2677: -0.006920\n",
      "  -> Downstream 545: -0.003995\n",
      "  -> Downstream 3921: 0.001916\n",
      "  -> Downstream 2380: -0.001712\n",
      "  -> Downstream 1233: 0.001483\n",
      "  -> Downstream 1489: 0.001366\n",
      "  -> Downstream 2486: 0.001192\n",
      "  -> Downstream 2775: -0.001053\n",
      "  -> Downstream 1244: -0.001045\n",
      "  -> Downstream 1835: -0.000962\n",
      "  -> Downstream 3642: -0.000884\n",
      "  -> Downstream 431: -0.000874\n",
      "  -> Downstream 1815: 0.000636\n",
      "  -> Downstream 4083: -0.000583\n",
      "  -> Downstream 2662: 0.000455\n",
      "  -> Downstream 3682: -0.000371\n",
      "  -> Downstream 488: -0.000302\n",
      "  -> Downstream 3319: -0.000268\n",
      "  -> Downstream 3092: 0.000268\n",
      "  -> Downstream 3102: 0.000249\n",
      "  -> Downstream 3381: 0.000240\n",
      "  -> Downstream 3716: 0.000237\n",
      "  -> Downstream 1575: 0.000224\n",
      "  -> Downstream 2524: 0.000188\n",
      "  -> Downstream 3368: -0.000176\n",
      "  -> Downstream 2862: -0.000158\n",
      "  -> Downstream 2693: -0.000120\n",
      "  -> Downstream 1586: -0.000119\n",
      "  -> Downstream 2041: -0.000116\n",
      "  -> Downstream 312: -0.000115\n",
      "  -> Downstream 2166: 0.000109\n",
      "  -> Downstream 2594: -0.000099\n",
      "  -> Downstream 3864: 0.000091\n",
      "  -> Downstream 4042: 0.000067\n",
      "  -> Downstream 576: -0.000067\n",
      "  -> Downstream 2209: -0.000051\n",
      "  -> Downstream 2576: 0.000038\n",
      "  -> Downstream 2675: 0.000014\n",
      "  -> Downstream 3997: 0.000011\n",
      "  -> Downstream 1605: -0.000003\n",
      "\n",
      "Upstream feature 3153:\n",
      "  -> Downstream 3921: -0.002317\n",
      "  -> Downstream 3384: 0.002261\n",
      "  -> Downstream 1575: 0.001213\n",
      "  -> Downstream 2677: -0.001003\n",
      "  -> Downstream 2775: -0.000936\n",
      "  -> Downstream 2486: 0.000753\n",
      "  -> Downstream 488: -0.000752\n",
      "  -> Downstream 1489: 0.000704\n",
      "  -> Downstream 3092: 0.000699\n",
      "  -> Downstream 3381: -0.000597\n",
      "  -> Downstream 3319: -0.000520\n",
      "  -> Downstream 2662: 0.000398\n",
      "  -> Downstream 2693: -0.000388\n",
      "  -> Downstream 2380: -0.000384\n",
      "  -> Downstream 1835: -0.000366\n",
      "  -> Downstream 2209: -0.000332\n",
      "  -> Downstream 431: -0.000329\n",
      "  -> Downstream 545: -0.000317\n",
      "  -> Downstream 1591: -0.000313\n",
      "  -> Downstream 1815: -0.000313\n",
      "  -> Downstream 3682: 0.000250\n",
      "  -> Downstream 1586: 0.000229\n",
      "  -> Downstream 3368: -0.000222\n",
      "  -> Downstream 4083: -0.000186\n",
      "  -> Downstream 1244: -0.000183\n",
      "  -> Downstream 2576: 0.000182\n",
      "  -> Downstream 3864: -0.000176\n",
      "  -> Downstream 1605: -0.000159\n",
      "  -> Downstream 2524: -0.000153\n",
      "  -> Downstream 3102: 0.000148\n",
      "  -> Downstream 2862: -0.000144\n",
      "  -> Downstream 2041: -0.000105\n",
      "  -> Downstream 3642: -0.000097\n",
      "  -> Downstream 3997: -0.000096\n",
      "  -> Downstream 576: -0.000090\n",
      "  -> Downstream 1233: -0.000089\n",
      "  -> Downstream 312: 0.000085\n",
      "  -> Downstream 2675: -0.000065\n",
      "  -> Downstream 2166: -0.000045\n",
      "  -> Downstream 2594: -0.000034\n",
      "  -> Downstream 3716: -0.000031\n",
      "  -> Downstream 4042: -0.000002\n",
      "\n",
      "Upstream feature 3177:\n",
      "  -> Downstream 545: -0.000819\n",
      "  -> Downstream 488: 0.000803\n",
      "  -> Downstream 2486: -0.000584\n",
      "  -> Downstream 3319: 0.000564\n",
      "  -> Downstream 3384: -0.000369\n",
      "  -> Downstream 3092: -0.000294\n",
      "  -> Downstream 2693: 0.000273\n",
      "  -> Downstream 1815: 0.000249\n",
      "  -> Downstream 3642: -0.000241\n",
      "  -> Downstream 1605: 0.000232\n",
      "  -> Downstream 3716: 0.000230\n",
      "  -> Downstream 2677: 0.000222\n",
      "  -> Downstream 2524: 0.000208\n",
      "  -> Downstream 576: 0.000197\n",
      "  -> Downstream 312: 0.000180\n",
      "  -> Downstream 2662: -0.000171\n",
      "  -> Downstream 2041: 0.000165\n",
      "  -> Downstream 431: 0.000165\n",
      "  -> Downstream 3381: 0.000163\n",
      "  -> Downstream 1591: 0.000148\n",
      "  -> Downstream 3102: 0.000142\n",
      "  -> Downstream 2209: 0.000114\n",
      "  -> Downstream 1233: 0.000103\n",
      "  -> Downstream 4083: 0.000095\n",
      "  -> Downstream 3682: -0.000090\n",
      "  -> Downstream 2166: -0.000087\n",
      "  -> Downstream 1489: 0.000085\n",
      "  -> Downstream 2862: 0.000085\n",
      "  -> Downstream 3997: 0.000078\n",
      "  -> Downstream 3368: 0.000076\n",
      "  -> Downstream 4042: -0.000074\n",
      "  -> Downstream 2594: 0.000074\n",
      "  -> Downstream 2675: 0.000060\n",
      "  -> Downstream 1835: 0.000056\n",
      "  -> Downstream 1575: -0.000048\n",
      "  -> Downstream 3864: 0.000044\n",
      "  -> Downstream 1244: -0.000042\n",
      "  -> Downstream 3921: 0.000040\n",
      "  -> Downstream 2576: -0.000030\n",
      "  -> Downstream 2380: -0.000017\n",
      "  -> Downstream 1586: -0.000013\n",
      "\n",
      "Upstream feature 3326:\n",
      "  -> Downstream 431: 0.002881\n",
      "  -> Downstream 1575: -0.002619\n",
      "  -> Downstream 2486: -0.002226\n",
      "  -> Downstream 488: 0.002172\n",
      "  -> Downstream 3384: -0.001997\n",
      "  -> Downstream 2677: 0.001909\n",
      "  -> Downstream 545: 0.001666\n",
      "  -> Downstream 3381: 0.001629\n",
      "  -> Downstream 2662: -0.001426\n",
      "  -> Downstream 3092: -0.001401\n",
      "  -> Downstream 3319: 0.001196\n",
      "  -> Downstream 2693: 0.000864\n",
      "  -> Downstream 1489: 0.000711\n",
      "  -> Downstream 2209: 0.000638\n",
      "  -> Downstream 1605: 0.000594\n",
      "  -> Downstream 2166: -0.000539\n",
      "  -> Downstream 2775: -0.000498\n",
      "  -> Downstream 3642: -0.000469\n",
      "  -> Downstream 2041: 0.000466\n",
      "  -> Downstream 3368: 0.000384\n",
      "  -> Downstream 2524: 0.000383\n",
      "  -> Downstream 2862: 0.000305\n",
      "  -> Downstream 1591: -0.000302\n",
      "  -> Downstream 2675: 0.000300\n",
      "  -> Downstream 3102: 0.000293\n",
      "  -> Downstream 3716: 0.000259\n",
      "  -> Downstream 1586: -0.000254\n",
      "  -> Downstream 3997: 0.000201\n",
      "  -> Downstream 4042: -0.000197\n",
      "  -> Downstream 2380: 0.000193\n",
      "  -> Downstream 3864: 0.000184\n",
      "  -> Downstream 1835: 0.000166\n",
      "  -> Downstream 1233: -0.000149\n",
      "  -> Downstream 3682: -0.000106\n",
      "  -> Downstream 2594: 0.000084\n",
      "  -> Downstream 3921: -0.000071\n",
      "  -> Downstream 4083: -0.000046\n",
      "  -> Downstream 2576: -0.000038\n",
      "  -> Downstream 312: 0.000027\n",
      "  -> Downstream 1815: 0.000003\n",
      "  -> Downstream 576: 0.000003\n",
      "\n",
      "Upstream feature 3343:\n",
      "  -> Downstream 2677: -0.004343\n",
      "  -> Downstream 3384: 0.003736\n",
      "  -> Downstream 3642: -0.001275\n",
      "  -> Downstream 1489: 0.000848\n",
      "  -> Downstream 2380: -0.000775\n",
      "  -> Downstream 431: -0.000712\n",
      "  -> Downstream 2775: -0.000698\n",
      "  -> Downstream 488: -0.000606\n",
      "  -> Downstream 1575: 0.000565\n",
      "  -> Downstream 1244: -0.000564\n",
      "  -> Downstream 3921: 0.000547\n",
      "  -> Downstream 1815: 0.000412\n",
      "  -> Downstream 2486: 0.000395\n",
      "  -> Downstream 545: -0.000335\n",
      "  -> Downstream 1835: -0.000323\n",
      "  -> Downstream 4083: -0.000304\n",
      "  -> Downstream 3716: 0.000178\n",
      "  -> Downstream 2209: -0.000171\n",
      "  -> Downstream 3092: 0.000160\n",
      "  -> Downstream 3319: -0.000152\n",
      "  -> Downstream 3864: -0.000129\n",
      "  -> Downstream 2662: 0.000098\n",
      "  -> Downstream 3368: -0.000095\n",
      "  -> Downstream 1233: -0.000091\n",
      "  -> Downstream 312: -0.000079\n",
      "  -> Downstream 2862: -0.000077\n",
      "  -> Downstream 3102: 0.000072\n",
      "  -> Downstream 1586: 0.000069\n",
      "  -> Downstream 2166: 0.000060\n",
      "  -> Downstream 576: 0.000060\n",
      "  -> Downstream 2524: -0.000056\n",
      "  -> Downstream 2576: 0.000051\n",
      "  -> Downstream 1591: -0.000051\n",
      "  -> Downstream 3682: -0.000037\n",
      "  -> Downstream 4042: 0.000018\n",
      "  -> Downstream 1605: 0.000014\n",
      "  -> Downstream 2675: 0.000014\n",
      "  -> Downstream 2041: -0.000014\n",
      "  -> Downstream 2693: -0.000013\n",
      "  -> Downstream 3997: 0.000011\n",
      "  -> Downstream 3381: 0.000011\n",
      "  -> Downstream 2594: -0.000010\n",
      "\n",
      "Upstream feature 3351:\n",
      "  -> Downstream 3384: 0.006620\n",
      "  -> Downstream 3921: 0.003603\n",
      "  -> Downstream 2775: -0.001505\n",
      "  -> Downstream 4083: 0.001411\n",
      "  -> Downstream 1591: -0.001308\n",
      "  -> Downstream 1233: -0.000991\n",
      "  -> Downstream 1815: 0.000948\n",
      "  -> Downstream 1575: 0.000841\n",
      "  -> Downstream 431: 0.000775\n",
      "  -> Downstream 2486: -0.000610\n",
      "  -> Downstream 2209: -0.000595\n",
      "  -> Downstream 2166: 0.000524\n",
      "  -> Downstream 545: -0.000433\n",
      "  -> Downstream 3092: 0.000407\n",
      "  -> Downstream 2041: -0.000395\n",
      "  -> Downstream 3642: -0.000296\n",
      "  -> Downstream 3381: 0.000279\n",
      "  -> Downstream 3319: -0.000272\n",
      "  -> Downstream 2693: -0.000271\n",
      "  -> Downstream 488: -0.000237\n",
      "  -> Downstream 2524: -0.000220\n",
      "  -> Downstream 3102: 0.000214\n",
      "  -> Downstream 2677: 0.000190\n",
      "  -> Downstream 1586: 0.000185\n",
      "  -> Downstream 2380: 0.000170\n",
      "  -> Downstream 1489: 0.000165\n",
      "  -> Downstream 3716: -0.000152\n",
      "  -> Downstream 3864: 0.000134\n",
      "  -> Downstream 2862: -0.000119\n",
      "  -> Downstream 1244: 0.000119\n",
      "  -> Downstream 3682: 0.000102\n",
      "  -> Downstream 4042: -0.000094\n",
      "  -> Downstream 1605: -0.000085\n",
      "  -> Downstream 576: -0.000071\n",
      "  -> Downstream 2576: 0.000071\n",
      "  -> Downstream 1835: 0.000066\n",
      "  -> Downstream 3997: -0.000037\n",
      "  -> Downstream 2675: 0.000035\n",
      "  -> Downstream 2594: 0.000023\n",
      "  -> Downstream 312: -0.000016\n",
      "  -> Downstream 3368: 0.000016\n",
      "  -> Downstream 2662: -0.000003\n",
      "\n",
      "Upstream feature 3480:\n",
      "  -> Downstream 1575: 0.001355\n",
      "  -> Downstream 545: -0.000894\n",
      "  -> Downstream 2486: 0.000804\n",
      "  -> Downstream 488: -0.000762\n",
      "  -> Downstream 3381: -0.000579\n",
      "  -> Downstream 4083: -0.000448\n",
      "  -> Downstream 2677: -0.000328\n",
      "  -> Downstream 2041: -0.000323\n",
      "  -> Downstream 1591: 0.000320\n",
      "  -> Downstream 2209: -0.000227\n",
      "  -> Downstream 1489: -0.000202\n",
      "  -> Downstream 3384: 0.000189\n",
      "  -> Downstream 2662: 0.000179\n",
      "  -> Downstream 3092: 0.000147\n",
      "  -> Downstream 1233: 0.000136\n",
      "  -> Downstream 2675: -0.000124\n",
      "  -> Downstream 2775: 0.000124\n",
      "  -> Downstream 1605: -0.000122\n",
      "  -> Downstream 576: 0.000115\n",
      "  -> Downstream 3368: -0.000111\n",
      "  -> Downstream 4042: 0.000110\n",
      "  -> Downstream 3716: -0.000104\n",
      "  -> Downstream 2380: -0.000101\n",
      "  -> Downstream 1815: -0.000090\n",
      "  -> Downstream 3319: -0.000075\n",
      "  -> Downstream 3864: 0.000075\n",
      "  -> Downstream 2862: -0.000069\n",
      "  -> Downstream 2524: -0.000066\n",
      "  -> Downstream 1586: 0.000064\n",
      "  -> Downstream 3682: 0.000050\n",
      "  -> Downstream 3921: -0.000045\n",
      "  -> Downstream 3642: 0.000042\n",
      "  -> Downstream 2594: -0.000029\n",
      "  -> Downstream 312: 0.000029\n",
      "  -> Downstream 1244: 0.000027\n",
      "  -> Downstream 1835: -0.000026\n",
      "  -> Downstream 3997: 0.000024\n",
      "  -> Downstream 431: 0.000019\n",
      "  -> Downstream 3102: 0.000014\n",
      "  -> Downstream 2576: 0.000010\n",
      "  -> Downstream 2693: -0.000005\n",
      "  -> Downstream 2166: 0.000005\n",
      "\n",
      "Upstream feature 3612:\n",
      "  -> Downstream 545: 0.003853\n",
      "  -> Downstream 3384: -0.001948\n",
      "  -> Downstream 1575: -0.001888\n",
      "  -> Downstream 2775: 0.001429\n",
      "  -> Downstream 2486: -0.001241\n",
      "  -> Downstream 4083: 0.001140\n",
      "  -> Downstream 3921: -0.001134\n",
      "  -> Downstream 1489: -0.001010\n",
      "  -> Downstream 2662: -0.000944\n",
      "  -> Downstream 431: 0.000834\n",
      "  -> Downstream 2693: 0.000830\n",
      "  -> Downstream 2524: 0.000627\n",
      "  -> Downstream 3092: -0.000625\n",
      "  -> Downstream 576: 0.000525\n",
      "  -> Downstream 488: 0.000510\n",
      "  -> Downstream 1591: -0.000503\n",
      "  -> Downstream 2677: 0.000496\n",
      "  -> Downstream 1815: -0.000419\n",
      "  -> Downstream 2209: 0.000418\n",
      "  -> Downstream 3716: 0.000384\n",
      "  -> Downstream 2041: -0.000347\n",
      "  -> Downstream 3368: 0.000322\n",
      "  -> Downstream 2380: -0.000295\n",
      "  -> Downstream 1244: -0.000289\n",
      "  -> Downstream 1233: 0.000268\n",
      "  -> Downstream 3319: 0.000267\n",
      "  -> Downstream 3864: 0.000264\n",
      "  -> Downstream 3997: 0.000260\n",
      "  -> Downstream 4042: 0.000255\n",
      "  -> Downstream 3102: -0.000250\n",
      "  -> Downstream 3642: 0.000243\n",
      "  -> Downstream 2166: -0.000236\n",
      "  -> Downstream 2675: 0.000230\n",
      "  -> Downstream 1586: -0.000166\n",
      "  -> Downstream 312: 0.000163\n",
      "  -> Downstream 2594: -0.000094\n",
      "  -> Downstream 1605: 0.000080\n",
      "  -> Downstream 3682: -0.000077\n",
      "  -> Downstream 2862: -0.000063\n",
      "  -> Downstream 2576: -0.000056\n",
      "  -> Downstream 1835: 0.000010\n",
      "\n",
      "Upstream feature 3634:\n",
      "  -> Downstream 2677: -0.006893\n",
      "  -> Downstream 3384: 0.005614\n",
      "  -> Downstream 2775: -0.001743\n",
      "  -> Downstream 3921: 0.001705\n",
      "  -> Downstream 1575: 0.001569\n",
      "  -> Downstream 488: -0.001506\n",
      "  -> Downstream 431: -0.001480\n",
      "  -> Downstream 2380: -0.001386\n",
      "  -> Downstream 2486: 0.001213\n",
      "  -> Downstream 545: -0.000960\n",
      "  -> Downstream 4083: -0.000901\n",
      "  -> Downstream 2662: 0.000889\n",
      "  -> Downstream 1244: -0.000888\n",
      "  -> Downstream 1835: -0.000845\n",
      "  -> Downstream 1815: 0.000752\n",
      "  -> Downstream 1489: 0.000620\n",
      "  -> Downstream 3642: -0.000510\n",
      "  -> Downstream 3319: -0.000473\n",
      "  -> Downstream 3716: 0.000409\n",
      "  -> Downstream 3092: 0.000360\n",
      "  -> Downstream 2209: -0.000316\n",
      "  -> Downstream 2166: 0.000314\n",
      "  -> Downstream 3864: -0.000306\n",
      "  -> Downstream 1233: 0.000289\n",
      "  -> Downstream 3368: -0.000205\n",
      "  -> Downstream 2041: -0.000189\n",
      "  -> Downstream 2693: -0.000186\n",
      "  -> Downstream 3102: -0.000181\n",
      "  -> Downstream 1605: -0.000175\n",
      "  -> Downstream 312: -0.000146\n",
      "  -> Downstream 2862: -0.000146\n",
      "  -> Downstream 3682: -0.000133\n",
      "  -> Downstream 1591: 0.000109\n",
      "  -> Downstream 3381: 0.000072\n",
      "  -> Downstream 1586: 0.000070\n",
      "  -> Downstream 2594: -0.000064\n",
      "  -> Downstream 4042: 0.000061\n",
      "  -> Downstream 2576: 0.000060\n",
      "  -> Downstream 3997: -0.000025\n",
      "  -> Downstream 576: 0.000015\n",
      "  -> Downstream 2524: 0.000014\n",
      "  -> Downstream 2675: -0.000011\n",
      "\n",
      "Upstream feature 3651:\n",
      "  -> Downstream 2677: 0.006359\n",
      "  -> Downstream 431: 0.002776\n",
      "  -> Downstream 1575: -0.002775\n",
      "  -> Downstream 3384: -0.002145\n",
      "  -> Downstream 545: 0.001448\n",
      "  -> Downstream 488: 0.001368\n",
      "  -> Downstream 2380: 0.001114\n",
      "  -> Downstream 3092: -0.001090\n",
      "  -> Downstream 3319: 0.000940\n",
      "  -> Downstream 1244: 0.000906\n",
      "  -> Downstream 4083: 0.000862\n",
      "  -> Downstream 3102: 0.000711\n",
      "  -> Downstream 3864: 0.000683\n",
      "  -> Downstream 2775: -0.000655\n",
      "  -> Downstream 1489: -0.000589\n",
      "  -> Downstream 2662: -0.000570\n",
      "  -> Downstream 2524: 0.000546\n",
      "  -> Downstream 2209: 0.000540\n",
      "  -> Downstream 2166: 0.000532\n",
      "  -> Downstream 1591: 0.000524\n",
      "  -> Downstream 1835: 0.000473\n",
      "  -> Downstream 2675: 0.000465\n",
      "  -> Downstream 3381: 0.000440\n",
      "  -> Downstream 1815: -0.000426\n",
      "  -> Downstream 3368: 0.000382\n",
      "  -> Downstream 3682: -0.000296\n",
      "  -> Downstream 1233: -0.000292\n",
      "  -> Downstream 3642: 0.000281\n",
      "  -> Downstream 1586: -0.000259\n",
      "  -> Downstream 1605: 0.000229\n",
      "  -> Downstream 312: 0.000226\n",
      "  -> Downstream 2594: 0.000212\n",
      "  -> Downstream 2486: -0.000205\n",
      "  -> Downstream 2693: 0.000161\n",
      "  -> Downstream 4042: -0.000140\n",
      "  -> Downstream 3997: 0.000099\n",
      "  -> Downstream 3921: -0.000094\n",
      "  -> Downstream 2862: 0.000071\n",
      "  -> Downstream 2576: -0.000039\n",
      "  -> Downstream 3716: -0.000021\n",
      "  -> Downstream 2041: -0.000016\n",
      "\n",
      "Upstream feature 3701:\n",
      "  -> Downstream 2677: 0.002258\n",
      "  -> Downstream 3384: -0.002176\n",
      "  -> Downstream 1591: -0.001128\n",
      "  -> Downstream 2662: -0.000914\n",
      "  -> Downstream 2486: -0.000913\n",
      "  -> Downstream 1489: -0.000896\n",
      "  -> Downstream 1575: -0.000885\n",
      "  -> Downstream 1815: -0.000603\n",
      "  -> Downstream 1244: 0.000536\n",
      "  -> Downstream 3642: 0.000502\n",
      "  -> Downstream 4083: 0.000427\n",
      "  -> Downstream 3864: 0.000383\n",
      "  -> Downstream 545: 0.000374\n",
      "  -> Downstream 3921: 0.000336\n",
      "  -> Downstream 1233: 0.000332\n",
      "  -> Downstream 2166: 0.000320\n",
      "  -> Downstream 1835: 0.000282\n",
      "  -> Downstream 3092: -0.000271\n",
      "  -> Downstream 488: 0.000235\n",
      "  -> Downstream 2041: 0.000231\n",
      "  -> Downstream 2209: 0.000223\n",
      "  -> Downstream 2693: 0.000171\n",
      "  -> Downstream 2675: 0.000165\n",
      "  -> Downstream 4042: -0.000155\n",
      "  -> Downstream 3102: -0.000096\n",
      "  -> Downstream 1586: -0.000085\n",
      "  -> Downstream 2524: -0.000084\n",
      "  -> Downstream 576: -0.000070\n",
      "  -> Downstream 3716: 0.000070\n",
      "  -> Downstream 2380: 0.000064\n",
      "  -> Downstream 1605: 0.000063\n",
      "  -> Downstream 312: 0.000057\n",
      "  -> Downstream 2576: 0.000055\n",
      "  -> Downstream 2775: -0.000052\n",
      "  -> Downstream 3682: -0.000049\n",
      "  -> Downstream 3997: 0.000044\n",
      "  -> Downstream 2594: 0.000038\n",
      "  -> Downstream 3319: -0.000026\n",
      "  -> Downstream 3368: 0.000026\n",
      "  -> Downstream 3381: 0.000018\n",
      "  -> Downstream 2862: 0.000010\n",
      "  -> Downstream 431: -0.000007\n",
      "\n",
      "Upstream feature 3764:\n",
      "  -> Downstream 3921: -0.001999\n",
      "  -> Downstream 545: 0.001577\n",
      "  -> Downstream 431: -0.000895\n",
      "  -> Downstream 1575: 0.000515\n",
      "  -> Downstream 2486: 0.000401\n",
      "  -> Downstream 2662: 0.000327\n",
      "  -> Downstream 4083: -0.000292\n",
      "  -> Downstream 3092: 0.000268\n",
      "  -> Downstream 3381: -0.000249\n",
      "  -> Downstream 1489: 0.000228\n",
      "  -> Downstream 488: -0.000226\n",
      "  -> Downstream 2677: -0.000193\n",
      "  -> Downstream 2775: 0.000160\n",
      "  -> Downstream 3319: -0.000158\n",
      "  -> Downstream 2209: -0.000123\n",
      "  -> Downstream 1605: -0.000122\n",
      "  -> Downstream 3716: -0.000117\n",
      "  -> Downstream 1591: -0.000115\n",
      "  -> Downstream 3384: -0.000112\n",
      "  -> Downstream 1835: -0.000101\n",
      "  -> Downstream 2693: -0.000098\n",
      "  -> Downstream 3864: -0.000089\n",
      "  -> Downstream 3368: -0.000088\n",
      "  -> Downstream 2380: -0.000080\n",
      "  -> Downstream 3642: 0.000078\n",
      "  -> Downstream 2524: -0.000077\n",
      "  -> Downstream 1586: 0.000055\n",
      "  -> Downstream 312: 0.000049\n",
      "  -> Downstream 2862: -0.000045\n",
      "  -> Downstream 3102: -0.000042\n",
      "  -> Downstream 3997: -0.000039\n",
      "  -> Downstream 3682: -0.000031\n",
      "  -> Downstream 4042: 0.000031\n",
      "  -> Downstream 576: -0.000027\n",
      "  -> Downstream 2576: 0.000025\n",
      "  -> Downstream 1233: 0.000022\n",
      "  -> Downstream 1244: 0.000017\n",
      "  -> Downstream 2041: -0.000015\n",
      "  -> Downstream 2594: -0.000005\n",
      "  -> Downstream 1815: -0.000004\n",
      "  -> Downstream 2166: -0.000001\n",
      "\n",
      "Upstream feature 3788:\n",
      "  -> Downstream 3921: -0.010544\n",
      "  -> Downstream 2677: 0.001019\n",
      "  -> Downstream 545: 0.000871\n",
      "  -> Downstream 3384: -0.000631\n",
      "  -> Downstream 1815: -0.000457\n",
      "  -> Downstream 2775: 0.000428\n",
      "  -> Downstream 1575: -0.000418\n",
      "  -> Downstream 4083: 0.000402\n",
      "  -> Downstream 2380: 0.000391\n",
      "  -> Downstream 488: 0.000297\n",
      "  -> Downstream 2662: -0.000291\n",
      "  -> Downstream 1489: -0.000287\n",
      "  -> Downstream 431: 0.000261\n",
      "  -> Downstream 3092: -0.000182\n",
      "  -> Downstream 1233: 0.000166\n",
      "  -> Downstream 3864: 0.000143\n",
      "  -> Downstream 1605: 0.000124\n",
      "  -> Downstream 1835: 0.000124\n",
      "  -> Downstream 1591: -0.000123\n",
      "  -> Downstream 2166: -0.000123\n",
      "  -> Downstream 3381: 0.000121\n",
      "  -> Downstream 1244: 0.000100\n",
      "  -> Downstream 2524: 0.000089\n",
      "  -> Downstream 2209: 0.000088\n",
      "  -> Downstream 576: 0.000073\n",
      "  -> Downstream 2486: -0.000065\n",
      "  -> Downstream 3716: -0.000062\n",
      "  -> Downstream 3642: 0.000060\n",
      "  -> Downstream 3102: 0.000055\n",
      "  -> Downstream 3997: 0.000052\n",
      "  -> Downstream 3319: 0.000046\n",
      "  -> Downstream 3368: 0.000045\n",
      "  -> Downstream 2675: -0.000040\n",
      "  -> Downstream 3682: 0.000037\n",
      "  -> Downstream 2693: 0.000033\n",
      "  -> Downstream 2862: 0.000026\n",
      "  -> Downstream 2041: 0.000021\n",
      "  -> Downstream 2594: -0.000021\n",
      "  -> Downstream 1586: 0.000020\n",
      "  -> Downstream 2576: -0.000010\n",
      "  -> Downstream 4042: 0.000004\n",
      "\n",
      "Upstream feature 3832:\n",
      "  -> Downstream 2677: 0.003874\n",
      "  -> Downstream 545: 0.003577\n",
      "  -> Downstream 431: 0.003176\n",
      "  -> Downstream 3384: -0.002923\n",
      "  -> Downstream 3921: 0.002217\n",
      "  -> Downstream 1489: -0.001958\n",
      "  -> Downstream 1233: -0.001415\n",
      "  -> Downstream 3092: -0.001257\n",
      "  -> Downstream 2486: -0.001254\n",
      "  -> Downstream 1575: -0.001104\n",
      "  -> Downstream 4083: 0.001012\n",
      "  -> Downstream 2775: -0.000906\n",
      "  -> Downstream 1591: -0.000884\n",
      "  -> Downstream 2662: -0.000784\n",
      "  -> Downstream 488: 0.000760\n",
      "  -> Downstream 1244: 0.000724\n",
      "  -> Downstream 1815: 0.000721\n",
      "  -> Downstream 3319: 0.000677\n",
      "  -> Downstream 2166: 0.000622\n",
      "  -> Downstream 1835: 0.000608\n",
      "  -> Downstream 3381: 0.000550\n",
      "  -> Downstream 2380: 0.000504\n",
      "  -> Downstream 3682: -0.000471\n",
      "  -> Downstream 1605: 0.000450\n",
      "  -> Downstream 2209: 0.000406\n",
      "  -> Downstream 3368: 0.000323\n",
      "  -> Downstream 2675: 0.000301\n",
      "  -> Downstream 2524: 0.000269\n",
      "  -> Downstream 2693: 0.000267\n",
      "  -> Downstream 2862: 0.000216\n",
      "  -> Downstream 3102: 0.000194\n",
      "  -> Downstream 3864: 0.000184\n",
      "  -> Downstream 2041: -0.000159\n",
      "  -> Downstream 3642: -0.000148\n",
      "  -> Downstream 2576: -0.000118\n",
      "  -> Downstream 576: 0.000109\n",
      "  -> Downstream 2594: 0.000099\n",
      "  -> Downstream 312: -0.000092\n",
      "  -> Downstream 3997: -0.000070\n",
      "  -> Downstream 3716: -0.000047\n",
      "  -> Downstream 4042: -0.000034\n",
      "\n",
      "\n",
      "Top 10 strongest connections overall:\n",
      "==================================================\n",
      " 1. Up 1297 -> Down 3384: -0.016360\n",
      " 2. Up 3788 -> Down 3921: -0.010544\n",
      " 3. Up 1297 -> Down 2677: 0.008073\n",
      " 4. Up 237 -> Down 545: 0.007893\n",
      " 5. Up 2956 -> Down 3384: 0.007671\n",
      " 6. Up 2672 -> Down 3384: 0.007139\n",
      " 7. Up 2956 -> Down 2677: -0.006920\n",
      " 8. Up 3634 -> Down 2677: -0.006893\n",
      " 9. Up 3351 -> Down 3384: 0.006620\n",
      "10. Up 2672 -> Down 2677: -0.006552\n"
     ]
    }
   ],
   "source": [
    "# Print edge tensor in a readable format\n",
    "print(\"\\n=== Edge Tensor Analysis ===\")\n",
    "print(f\"Edge tensor shape: {edge_tensor.shape}\")\n",
    "print(f\"Number of non-zero entries: {edge_tensor._nnz()}\")\n",
    "\n",
    "if edge_tensor._nnz() > 0:\n",
    "    # Get the indices and values\n",
    "    indices = edge_tensor.indices()  # [2, nnz] - [down_idx, up_idx]\n",
    "    values = edge_tensor.values()    # [nnz]\n",
    "    \n",
    "    # Convert to lists for easier processing\n",
    "    down_indices = indices[0].tolist()\n",
    "    up_indices = indices[1].tolist()\n",
    "    edge_values = values.tolist()\n",
    "    \n",
    "    # Group by upstream feature index\n",
    "    from collections import defaultdict\n",
    "    up_to_down = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(down_indices)):\n",
    "        down_idx = down_indices[i]\n",
    "        up_idx = up_indices[i]\n",
    "        val = edge_values[i]\n",
    "        up_to_down[up_idx].append((down_idx, val))\n",
    "    \n",
    "    # Sort upstream indices for consistent output\n",
    "    sorted_up_indices = sorted(up_to_down.keys())\n",
    "    \n",
    "    print(f\"\\nEdge connections (upstream -> downstream):\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for up_idx in sorted_up_indices:\n",
    "        connections = up_to_down[up_idx]\n",
    "        # Sort connections by absolute value (strongest first)\n",
    "        connections.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        print(f\"\\nUpstream feature {up_idx}:\")\n",
    "        for down_idx, val in connections:\n",
    "            print(f\"  -> Downstream {down_idx}: {val:.6f}\")\n",
    "    \n",
    "    # Also show top connections overall\n",
    "    print(f\"\\n\\nTop 10 strongest connections overall:\")\n",
    "    print(\"=\"*50)\n",
    "    all_connections = [(up_idx, down_idx, val) for up_idx, connections in up_to_down.items() \n",
    "                       for down_idx, val in connections]\n",
    "    all_connections.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    \n",
    "    for i, (up_idx, down_idx, val) in enumerate(all_connections[:10]):\n",
    "        print(f\"{i+1:2d}. Up {up_idx} -> Down {down_idx}: {val:.6f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No edges found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
